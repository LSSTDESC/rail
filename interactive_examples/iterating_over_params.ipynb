{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734bc530",
   "metadata": {},
   "source": [
    "# Iterating over parameters and comparing resulting distributions of redshifts\n",
    "\n",
    "**Authors:** Jennifer Scora\n",
    "\n",
    "**Last run successfully:** Jan 16, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff773db",
   "metadata": {},
   "source": [
    "This notebook shows how to run through the various stages of RAIL (creation, estimation, evaluation and summarization) while looping over a specific parameter and comparing the resulting photometric redshift estimates. It also will show how to use multiprocessing with the interactive mode (if you want full MPI, or are running on very large datasets, we recommend running in pipeline mode (link))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30b1b6",
   "metadata": {},
   "source": [
    "## Creating the data \n",
    "First we want to create the data sets of galaxy magnitudes that we will use to estimate photometric redshifts. We will use PZflow to generate our model, and then pull two data sets from the model, a training dataset and a test dataset. The training data set will be used to train our models, and the test data set is the data we will get photo-z estimates for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7101fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEPHAREDIR is being set to the default cache directory:\n",
      "/home/jscora/.cache/lephare/data\n",
      "More than 1Gb may be written there.\n",
      "LEPHAREWORK is being set to the default cache directory:\n",
      "/home/jscora/.cache/lephare/work\n",
      "Default work cache is already linked. \n",
      "This is linked to the run directory:\n",
      "/home/jscora/.cache/lephare/runs/20250327T165906\n"
     ]
    }
   ],
   "source": [
    "import rail.interactive as ri \n",
    "import numpy as np\n",
    "import tables_io\n",
    "from pzflow.examples import get_galaxy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3be41b",
   "metadata": {},
   "source": [
    "Here we need a few configuration parameters to deal with differences in data schema between existing PZ codes. We also need to grab the data to use for training the flow engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a41d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "rename_dict = {f\"mag_{band}_lsst_err\": f\"mag_err_{band}_lsst\" for band in bands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b76e0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = get_galaxy_data().rename(band_dict, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba3db0",
   "metadata": {},
   "source": [
    "### Train and sample the model\n",
    "\n",
    "Here we need to train the normalizing flow that serves as the engine for the input data creation, and then use the flow to produce some synthetic data for our training data set, as well as for our test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0adc3048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, FlowModeler\n",
      "Training 30 epochs \n",
      "Loss:\n",
      "(0) 21.3266\n",
      "(1) 3.9686\n",
      "(2) 1.9351\n",
      "(3) 5.2006\n",
      "(4) -0.3579\n",
      "(5) 2.2561\n",
      "(6) 1.5917\n",
      "(7) 0.3691\n",
      "(8) -1.0218\n",
      "(9) inf\n",
      "Training stopping after epoch 9 because training loss diverged.\n",
      "Inserting handle into data store.  model: inprogress_model.pkl, FlowModeler\n",
      "Inserting handle into data store.  model: <pzflow.flow.Flow object at 0x7316199196d0>, FlowCreator\n",
      "Inserting handle into data store.  output: inprogress_output.pq, FlowCreator\n",
      "Inserting handle into data store.  model: <pzflow.flow.Flow object at 0x7316199196d0>, FlowCreator\n",
      "Inserting handle into data store.  output: inprogress_output.pq, FlowCreator\n"
     ]
    }
   ],
   "source": [
    "flow_model = ri.creation.engines.flowEngine.flow_modeler(\n",
    "    input=catalog,\n",
    "    seed=0,\n",
    "    phys_cols={\"redshift\": [0, 3]},\n",
    "    phot_cols={\n",
    "        \"mag_u_lsst\": [17, 35],\n",
    "        \"mag_g_lsst\": [16, 32],\n",
    "        \"mag_r_lsst\": [15, 30],\n",
    "        \"mag_i_lsst\": [15, 30],\n",
    "        \"mag_z_lsst\": [14, 29],\n",
    "        \"mag_y_lsst\": [14, 28],\n",
    "    },\n",
    "    calc_colors={\"ref_column_name\": \"mag_i_lsst\"},\n",
    ")\n",
    "\n",
    "# get sample test and training data sets\n",
    "train_data_orig = ri.creation.engines.flowEngine.flow_creator(\n",
    "    n_samples=150, model=flow_model[\"model\"], seed=1235\n",
    ")\n",
    "test_data_orig = ri.creation.engines.flowEngine.flow_creator(\n",
    "    model=flow_model[\"model\"], n_samples=150, seed=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e519a8f",
   "metadata": {},
   "source": [
    "### Degrade the data sets\n",
    "\n",
    "Next we will apply some degradation functions to the data, to produce some erroneous input data and apply some cuts to the data to make it more like data that would come from a telescope. We are applying more degradation to the training set, including cuts to ensure our sample is incomplete. For both data sets, we use the `ColumnMapper` to rename the error columns so that they match the names in DC2, and use the `TableConverter` to convert the data to a numpy dictionary, so that it fits the expected input format for the following functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, LSSTErrorModel\n",
      "Inserting handle into data store.  output: inprogress_output.pq, LSSTErrorModel\n",
      "Inserting handle into data store.  input: None, InvRedshiftIncompleteness\n",
      "Inserting handle into data store.  output: inprogress_output.pq, InvRedshiftIncompleteness\n",
      "Inserting handle into data store.  input: None, LineConfusion\n",
      "Inserting handle into data store.  output: inprogress_output.pq, LineConfusion\n",
      "Inserting handle into data store.  input: None, QuantityCut\n",
      "Inserting handle into data store.  output: inprogress_output.pq, QuantityCut\n",
      "Inserting handle into data store.  input: None, ColumnMapper\n",
      "Inserting handle into data store.  output: inprogress_output.pq, ColumnMapper\n",
      "Inserting handle into data store.  input: None, TableConverter\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, TableConverter\n",
      "Inserting handle into data store.  input: None, LSSTErrorModel\n",
      "Inserting handle into data store.  output: inprogress_output.pq, LSSTErrorModel\n",
      "Inserting handle into data store.  input: None, ColumnMapper\n",
      "Inserting handle into data store.  output: inprogress_output.pq, ColumnMapper\n",
      "Inserting handle into data store.  input: None, TableConverter\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, TableConverter\n"
     ]
    }
   ],
   "source": [
    "### degrade training data\n",
    "# add photometric errors modelled on LSST to the data\n",
    "train_data_errs = ri.creation.degraders.photometric_errors.lsst_error_model(\n",
    "    input=train_data_orig[\"output\"], seed=66, renameDict=band_dict, ndFlag=np.nan\n",
    ")\n",
    "# randomly removes some galaxies above certain redshift threshold \n",
    "train_data_inc = (\n",
    "    ri.creation.degraders.spectroscopic_degraders.inv_redshift_incompleteness(\n",
    "        input=train_data_errs[\"output\"], pivot_redshift=1.0\n",
    "    )\n",
    ")\n",
    "# simulates the effect of misidentified lines \n",
    "train_data_conf = ri.creation.degraders.spectroscopic_degraders.line_confusion(\n",
    "    input=train_data_inc[\"output\"],\n",
    "    true_wavelen=5007.0,\n",
    "    wrong_wavelen=3727.0,\n",
    "    frac_wrong=0.05,\n",
    "    seed=1337,\n",
    ")\n",
    "# cut the data below a certain magnitude \n",
    "train_data_cut = ri.creation.degraders.quantityCut.quantity_cut(\n",
    "    input=train_data_conf[\"output\"], cuts={\"mag_i_lsst\": 25.0}\n",
    ")\n",
    "# renames error columns to match DC2\n",
    "train_data_pq = ri.tools.table_tools.column_mapper(\n",
    "    input=train_data_cut[\"output\"], columns=rename_dict\n",
    ")\n",
    "# converts output to a numpy dictionary\n",
    "train_data = ri.tools.table_tools.table_converter(\n",
    "    input=train_data_pq[\"output\"], output_format=\"numpyDict\"\n",
    ")\n",
    "\n",
    "### degrade testing data\n",
    "# add photometric errors modelled on LSST to the data\n",
    "test_data_errs = ri.creation.degraders.photometric_errors.lsst_error_model(\n",
    "    input=test_data_orig[\"output\"], seed=58, renameDict=band_dict, ndFlag=np.nan\n",
    ")\n",
    "# renames error columns to match DC2\n",
    "test_data_pq = ri.tools.table_tools.column_mapper(\n",
    "    input=test_data_errs[\"output\"], columns=rename_dict, hdf5_groupname=\"\"\n",
    ")\n",
    "# converts output to a numpy dictionary\n",
    "test_data = ri.tools.table_tools.table_converter(\n",
    "    input=test_data_pq[\"output\"], output_format=\"numpyDict\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165efba",
   "metadata": {},
   "source": [
    "## Estimate the redshifts and evaluate performance\n",
    "\n",
    "Now, we're going to estimate our photometric redshifts. Here is where we'll iterate over a set of parameters, so we can see how those parameters affect the performance of our redshift estimation algorithm. We're going to use the K-Nearest Neighbours algorithm (link) to estimate our redshifts, and we'll vary the minimum and maximum number of neighbours allowed. \n",
    "\n",
    "Then we'll evaluate how the estimated redshifts compare to the true redshifts, which is the original test data set before it was degraded. The results of the evaluation are saved to a dictionary, so we can compare them later. We'll also save the actual generated photometric redshifts to a dictionary so we can plot them later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f865a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=3\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x603b18018170>, 'bestsig': np.float64(0.075), 'nneigh': 3, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=3\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x603b1b778190>, 'bestsig': np.float64(0.075), 'nneigh': 3, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=3\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x603b1b7775a0>, 'bestsig': np.float64(0.075), 'nneigh': 3, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=4\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x603b1fc076f0>, 'bestsig': np.float64(0.075), 'nneigh': 4, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n"
     ]
    }
   ],
   "source": [
    "### Iterate over estimating photo-zs using KNN \n",
    "\n",
    "# set up parameters to iterate over and dictionaries to store data\n",
    "nb_params = [(3,7), (2,6), (2,8), (4,9)]\n",
    "eval_dict = {}\n",
    "photoz_dict = {}\n",
    "naive_dict = {}\n",
    "point_est_dict = {}\n",
    "\n",
    "for nb_min, nb_max in nb_params:\n",
    "    # train the informer\n",
    "    inform_knn = ri.estimation.algos.k_nearneigh.k_near_neig_informer(\n",
    "        input=train_data[\"output\"], nondetect_val=np.nan, model=\"bpz.pkl\", hdf5_groupname=\"\", nneigh_min=nb_min, nneigh_max=nb_max\n",
    "    )\n",
    "    # get photo-zs\n",
    "    knn_estimated = ri.estimation.algos.k_nearneigh.k_near_neig_estimator(\n",
    "        input=test_data[\"output\"],\n",
    "        model=inform_knn[\"model\"],\n",
    "        nondetect_val=np.nan,\n",
    "        hdf5_groupname=\"\",\n",
    "    )\n",
    "    # put in a dict for later\n",
    "    photoz_dict[(nb_min, nb_max)] = knn_estimated\n",
    "\n",
    "    ### Evaluate the results \n",
    "    evaluator_stage_dict = dict(\n",
    "        metrics=[\"cdeloss\", \"pit\", \"brier\"],\n",
    "        _random_state=None,\n",
    "        metric_config={\n",
    "            \"brier\": {\"limits\": (0, 3.1)},\n",
    "            \"pit\": {\"tdigest_compression\": 1000},\n",
    "        },\n",
    "    )\n",
    "    truth = test_data_orig\n",
    "\n",
    "    the_eval = ri.evaluation.dist_to_point_evaluator.dist_to_point_evaluator(\n",
    "            input={\"data\": knn_estimated[\"output\"], \"truth\": truth[\"output\"]\n",
    "            },\n",
    "            **evaluator_stage_dict,\n",
    "            hdf5_groupname=\"\",\n",
    "        )\n",
    "    \n",
    "    # put the evaluation results in a dictionary so we have them \n",
    "    eval_dict[(nb_min,nb_max)] = the_eval\n",
    "\n",
    "    # summarize the distributions using point estimate and naive stack summarizers \n",
    "    point_estimate_ens = ri.estimation.algos.point_est_hist.point_est_hist_summarizer(\n",
    "    input=knn_estimated[\"output\"]\n",
    "    )\n",
    "    point_est_dict[(nb_min,nb_max)] = point_estimate_ens\n",
    "    naive_stack_ens = ri.estimation.algos.naive_stack.naive_stack_summarizer(\n",
    "        input=knn_estimated[\"output\"]\n",
    "    )\n",
    "    naive_dict[(nb_min,nb_max)] = naive_stack_ens\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f3f56",
   "metadata": {},
   "source": [
    "## Compare the results\n",
    "\n",
    "We can take a look at the evaluation metrics that we've generated for each of the runs to see how they compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: either make this into a nicer table or get rid of it \n",
    "results_tables = {\n",
    "    key: tables_io.convertObj(val[\"summary\"], tables_io.types.PD_DATAFRAME)\n",
    "    for key, val in eval_dict.items()\n",
    "}\n",
    "results_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a73606",
   "metadata": {},
   "source": [
    "We can also plot the summarized distributions of all the photometric redshifts generated in a loop against each other, to compare the effect of the different parameters. Below, we plot the runs with the following parameters: \n",
    "- minimum neighbours: 3, maximum neighbours: 7\n",
    "- minimum neighbours: 2, maximum neighbours: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of point estimate summarized distribution \n",
    "# TODO: try putting these both on one plot \n",
    "point_est_dict[(3,7)][\"output\"].plot_native(xlim=(0, 3))\n",
    "point_est_dict[(2,6)][\"output\"].plot_native(xlim=(0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of naive stack summarized distribution \n",
    "naive_dict[(3,7)][\"output\"].plot_native(xlim=(0,3))\n",
    "naive_dict[(2,6)][\"output\"].plot_native(xlim=(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc501ed",
   "metadata": {},
   "source": [
    "## Using multiprocessing\n",
    "\n",
    "Let's say we wanted to do the same as above but with a lot more parameters (and perhaps with a slower algorithm). We can use the python `multiprocessing` module to run the whole loop concurrently, and speed up the process a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d894deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_photoz(nb_lims):\n",
    "    \"\"\"A function to estimate photo-zs using the KNN alorithm, given a minimum and maximum number of nearest neighbours. It will \n",
    "    then evaluate the performance \"\"\"\n",
    "\n",
    "    # nb_lims, train_data, test_data, inform_knn, test_data_orig = args[0], args[1][0], args[1][1], args[1][2]\n",
    "\n",
    "    # train the informer\n",
    "    inform_knn = ri.estimation.algos.k_nearneigh.k_near_neig_informer(\n",
    "        input=train_data[\"output\"], nondetect_val=np.nan, model=\"bpz.pkl\", hdf5_groupname=\"\", nneigh_min=nb_lims[0], nneigh_max=nb_lims[1]\n",
    "    )\n",
    "    # get photo-zs\n",
    "    knn_estimated = ri.estimation.algos.k_nearneigh.k_near_neig_estimator(\n",
    "        input=test_data[\"output\"],\n",
    "        model=inform_knn[\"model\"],\n",
    "        nondetect_val=np.nan,\n",
    "        hdf5_groupname=\"\",\n",
    "    )\n",
    "    # put in a dict for later\n",
    "    photoz_dict[(nb_lims[0], nb_lims[1])] = knn_estimated\n",
    "\n",
    "    ### Evaluate the results \n",
    "    evaluator_stage_dict = dict(\n",
    "        metrics=[\"cdeloss\", \"pit\", \"brier\"],\n",
    "        _random_state=None,\n",
    "        metric_config={\n",
    "            \"brier\": {\"limits\": (0, 3.1)},\n",
    "            \"pit\": {\"tdigest_compression\": 1000},\n",
    "        },\n",
    "    )\n",
    "    truth = test_data_orig\n",
    "\n",
    "    the_eval = ri.evaluation.dist_to_point_evaluator.dist_to_point_evaluator(\n",
    "            input={\"data\": knn_estimated[\"output\"], \"truth\": truth[\"output\"]\n",
    "            },\n",
    "            **evaluator_stage_dict,\n",
    "            hdf5_groupname=\"\",\n",
    "        )\n",
    "    \n",
    "    # put the evaluation results in a dictionary so we have them \n",
    "    eval_dict[(nb_lims[0],nb_lims[1])] = the_eval\n",
    "\n",
    "    # summarize the distributions using point estimate and naive stack summarizers \n",
    "    point_estimate_ens = ri.estimation.algos.point_est_hist.point_est_hist_summarizer(\n",
    "    input=knn_estimated[\"output\"]\n",
    "    )\n",
    "    point_est_dict[(nb_lims[0],nb_lims[1])] = point_estimate_ens\n",
    "    naive_stack_ens = ri.estimation.algos.naive_stack.naive_stack_summarizer(\n",
    "        input=knn_estimated[\"output\"]\n",
    "    )\n",
    "    naive_dict[(nb_lims[0],nb_lims[1])] = naive_stack_ens\n",
    "    return the_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88efba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=3\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x7315040a5d00>, 'bestsig': np.float64(0.075), 'nneigh': 3, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=3\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x73159c04ef40>, 'bestsig': np.float64(0.075), 'nneigh': 3, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n",
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n",
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n",
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=4\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x7315980a5d70>, 'bestsig': np.float64(0.075), 'nneigh': 4, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=3\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x7315ac08aa10>, 'bestsig': np.float64(0.075), 'nneigh': 3, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n",
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n",
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n",
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "{'output': {}, 'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])}, 'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}}\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "{'output': {}, 'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])}, 'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}}\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "{'output': {}, 'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])}, 'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}}\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  input: None, KNearNeighInformer\n",
      "split into 49 training and 16 validation samples\n",
      "finding best fit sigma and NNeigh...\n",
      "{'output': {}, 'summary': {'cdeloss': array([-0.44553651]), 'brier': array([176.7702214])}, 'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 91))}}\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=6\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x73159c068e80>, 'bestsig': np.float64(0.075), 'nneigh': 6, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n",
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=3\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x731504067920>, 'bestsig': np.float64(0.075), 'nneigh': 3, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n",
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=3\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x7315ac092420>, 'bestsig': np.float64(0.075), 'nneigh': 3, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "best fit values are sigma=0.075 and numneigh=3\n",
      "\n",
      "\n",
      "\n",
      "Inserting handle into data store.  model: inprogress_bpz.pkl, KNearNeighInformer\n",
      "Inserting handle into data store.  input: None, KNearNeighEstimator\n",
      "Inserting handle into data store.  model: {'kdtree': <sklearn.neighbors._kd_tree.KDTree object at 0x7315980a8ac0>, 'bestsig': np.float64(0.075), 'nneigh': 3, 'truezs': array([0.8559624 , 1.09725535, 0.67563593, 0.91550589, 0.90324795,\n",
      "       0.65226948, 0.77357709, 0.37648416, 1.22105432, 0.89333856,\n",
      "       0.65628129, 0.83754033, 1.04881907, 1.19360622, 0.41372049,\n",
      "       1.24091506, 0.07890534, 0.33354044, 0.84880698, 0.50793141,\n",
      "       0.07312357, 0.92710775, 0.53522396, 0.78664237, 0.55667555,\n",
      "       0.45270801, 0.50885946, 1.21598339, 0.55211103, 0.22890699,\n",
      "       0.49027538, 0.60366631, 0.66702271, 0.59513855, 0.67450702,\n",
      "       0.25323451, 1.34854114, 0.90114802, 0.46726322, 1.00304711,\n",
      "       0.76495528, 0.16585791, 0.70379937, 0.56558955, 0.61184895,\n",
      "       1.07242024, 0.59145719, 1.13781507, 0.84907597, 0.14287889,\n",
      "       1.44101179, 0.53706932, 0.43069077, 0.75349617, 1.58790886,\n",
      "       1.01622415, 1.43680556, 0.10903394, 1.01656866, 1.06943297,\n",
      "       1.01072514, 1.35482941, 0.97222292, 0.52210903, 0.68324316]), 'only_colors': False}, KNearNeighEstimator\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Process 0 estimating PZ PDF for rows 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, KNearNeighEstimator\n",
      "Inserting handle into data store.  input: None, DistToPointEvaluator\n",
      "Inserting handle into data store.  truth: None, DistToPointEvaluator\n",
      "Requested metrics: ['cdeloss', 'pit', 'brier']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Input predictions do not sum to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output: inprogress_output.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  summary: inprogress_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  single_distribution_summary: inprogress_single_distribution_summary.hdf5, DistToPointEvaluator\n",
      "Inserting handle into data store.  input: None, PointEstHistSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, PointEstHistSummarizer\n",
      "Inserting handle into data store.  input: None, NaiveStackSummarizer\n",
      "Process 0 running estimator on chunk 0 - 150\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "{'output': {}, 'summary': {'cdeloss': array([-0.55763654]), 'brier': array([156.11697065])}, 'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 92))}}\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "{'output': {}, 'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])}, 'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}}\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "{'output': {}, 'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])}, 'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}}\n",
      "Inserting handle into data store.  output: inprogress_output.hdf5, NaiveStackSummarizer\n",
      "Inserting handle into data store.  single_NZ: inprogress_single_NZ.hdf5, NaiveStackSummarizer\n",
      "{'output': {}, 'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])}, 'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}}\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "\n",
    "# set up parameters to iterate over and dictionaries to store data\n",
    "nb_params = [(3,7), (2,6), (2,8), (4,9),(5,10), (1,9), (2,9), (3,10)]\n",
    "nb_mins = [3,2,2,4,5,1,2,3]\n",
    "nb_maxs = [7,6,8,9,10,9,9,10]\n",
    "eval_dict = {}\n",
    "photoz_dict = {}\n",
    "naive_dict = {}\n",
    "point_est_dict = {}\n",
    "\n",
    "pool = Pool(4)\n",
    "for result in pool.imap_unordered(estimate_photoz, nb_params):\n",
    "    print(result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e9d19e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 6): {'output': {},\n",
       "  'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])},\n",
       "  'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}},\n",
       " (3, 7): {'output': {},\n",
       "  'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])},\n",
       "  'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}},\n",
       " (4, 9): {'output': {},\n",
       "  'summary': {'cdeloss': array([-0.44553651]), 'brier': array([176.7702214])},\n",
       "  'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 91))}},\n",
       " (2, 8): {'output': {},\n",
       "  'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])},\n",
       "  'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}},\n",
       " (5, 10): {'output': {},\n",
       "  'summary': {'cdeloss': array([-0.55763654]), 'brier': array([156.11697065])},\n",
       "  'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 92))}},\n",
       " (1, 9): {'output': {},\n",
       "  'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])},\n",
       "  'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}},\n",
       " (2, 9): {'output': {},\n",
       "  'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])},\n",
       "  'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}},\n",
       " (3, 10): {'output': {},\n",
       "  'summary': {'cdeloss': array([-0.25960067]), 'brier': array([198.97975105])},\n",
       "  'single_distribution_summary': {'pit': Ensemble(the_class=quant,shape=(1, 90))}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1171f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(2, 6), (3, 7), (2, 8), (4, 9), (5, 10), (1, 9), (2, 9), (3, 10)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f698163",
   "metadata": {},
   "source": [
    "### Large datasets\n",
    "\n",
    "If the code is slow because you're using extremely large datasets, or you're running into memory issues for the same reason, then we suggest using a pipeline. Pipelines are ideal for large datasets, as the code will chunk up large files and iterate through them as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d25679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
