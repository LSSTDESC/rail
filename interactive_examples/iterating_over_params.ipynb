{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734bc530",
   "metadata": {},
   "source": [
    "# Iterating over parameters and comparing resulting distributions of redshifts\n",
    "\n",
    "**Authors:** Jennifer Scora\n",
    "\n",
    "**Last run successfully:** Jan 16, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff773db",
   "metadata": {},
   "source": [
    "This notebook shows how to run through the various stages of RAIL (creation, estimation, and evaluation) while looping over a specific parameter and comparing the resulting photometric redshift estimates. It also will show how to use multiprocessing to speed up this iteration. However, if you want full MPI, or are running on very large datasets, we recommend running in pipeline mode (link)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30b1b6",
   "metadata": {},
   "source": [
    "## Creating the data \n",
    "First we want to create the data sets of galaxy magnitudes that we will use to estimate photometric redshifts. We will use PZflow to generate our model, and then pull two data sets from the model, a training dataset and a test dataset. The training data set will be used to train our models, and the test data set is the data we will get photo-z estimates for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7101fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail.interactive as ri \n",
    "import numpy as np\n",
    "import tables_io\n",
    "from pzflow.examples import get_galaxy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3be41b",
   "metadata": {},
   "source": [
    "Here we need a few configuration parameters to deal with differences in data schema between existing PZ codes. We also need to grab the data to use for training the flow engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a41d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "rename_dict = {f\"mag_{band}_lsst_err\": f\"mag_err_{band}_lsst\" for band in bands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = get_galaxy_data().rename(band_dict, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba3db0",
   "metadata": {},
   "source": [
    "### Train and sample the model\n",
    "\n",
    "Here we need to train the normalizing flow that serves as the engine for the input data creation, and then use the flow to produce some synthetic data for our training data set, as well as for our test data set. We will create small datasets of 150 galaxies each for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc3048",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_model = ri.creation.engines.flowEngine.flow_modeler(\n",
    "    input=catalog,\n",
    "    seed=0,\n",
    "    phys_cols={\"redshift\": [0, 3]},\n",
    "    phot_cols={\n",
    "        \"mag_u_lsst\": [17, 35],\n",
    "        \"mag_g_lsst\": [16, 32],\n",
    "        \"mag_r_lsst\": [15, 30],\n",
    "        \"mag_i_lsst\": [15, 30],\n",
    "        \"mag_z_lsst\": [14, 29],\n",
    "        \"mag_y_lsst\": [14, 28],\n",
    "    },\n",
    "    calc_colors={\"ref_column_name\": \"mag_i_lsst\"},\n",
    ")\n",
    "\n",
    "# get sample test and training data sets\n",
    "train_data_orig = ri.creation.engines.flowEngine.flow_creator(\n",
    "    n_samples=150, model=flow_model[\"model\"], seed=1235\n",
    ")\n",
    "test_data_orig = ri.creation.engines.flowEngine.flow_creator(\n",
    "    model=flow_model[\"model\"], n_samples=150, seed=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e519a8f",
   "metadata": {},
   "source": [
    "### Degrade the data sets\n",
    "\n",
    "Next we will apply some degradation functions to the data, to make it look more like real observations. We apply the following functions to the training data set:\n",
    "1. `LSSTErrorModel` to add photometric errors \n",
    "2. `InvRedshiftIncompleteness` to remove some galaxies above a redshift threshold\n",
    "3. `LineConfusion` to simulate the effect of misidentified lines \n",
    "4. `QuantityCut`cuts galaxies based on their specific band magnitudes \n",
    "\n",
    "We then use `ColumnMapper` to rename the error columns so that they match the names in DC2, and use `TableConverter` to convert the data to a numpy dictionary, so that it fits the expected input format for the following functions. \n",
    "\n",
    "For the test data set, we only apply the `LSSTErrorModel` degradations, as well as making the above structural changes to get the data in the same output format as the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcbbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### degrade training data\n",
    "# add photometric errors modelled on LSST to the data\n",
    "train_data_errs = ri.creation.degraders.photometric_errors.lsst_error_model(\n",
    "    input=train_data_orig[\"output\"], seed=66, renameDict=band_dict, ndFlag=np.nan\n",
    ")\n",
    "# randomly removes some galaxies above certain redshift threshold \n",
    "train_data_inc = (\n",
    "    ri.creation.degraders.spectroscopic_degraders.inv_redshift_incompleteness(\n",
    "        input=train_data_errs[\"output\"], pivot_redshift=1.0\n",
    "    )\n",
    ")\n",
    "# simulates the effect of misidentified lines \n",
    "train_data_conf = ri.creation.degraders.spectroscopic_degraders.line_confusion(\n",
    "    input=train_data_inc[\"output\"],\n",
    "    true_wavelen=5007.0,\n",
    "    wrong_wavelen=3727.0,\n",
    "    frac_wrong=0.05,\n",
    "    seed=1337,\n",
    ")\n",
    "# cut some of the data below a certain magnitude \n",
    "train_data_cut = ri.creation.degraders.quantityCut.quantity_cut(\n",
    "    input=train_data_conf[\"output\"], cuts={\"mag_i_lsst\": 25.0}\n",
    ")\n",
    "# renames error columns to match DC2\n",
    "train_data_pq = ri.tools.table_tools.column_mapper(\n",
    "    input=train_data_cut[\"output\"], columns=rename_dict\n",
    ")\n",
    "# converts output to a numpy dictionary\n",
    "train_data = ri.tools.table_tools.table_converter(\n",
    "    input=train_data_pq[\"output\"], output_format=\"numpyDict\"\n",
    ")\n",
    "\n",
    "### degrade testing data\n",
    "# add photometric errors modelled on LSST to the data\n",
    "test_data_errs = ri.creation.degraders.photometric_errors.lsst_error_model(\n",
    "    input=test_data_orig[\"output\"], seed=58, renameDict=band_dict, ndFlag=np.nan\n",
    ")\n",
    "# renames error columns to match DC2\n",
    "test_data_pq = ri.tools.table_tools.column_mapper(\n",
    "    input=test_data_errs[\"output\"], columns=rename_dict, hdf5_groupname=\"\"\n",
    ")\n",
    "# converts output to a numpy dictionary\n",
    "test_data = ri.tools.table_tools.table_converter(\n",
    "    input=test_data_pq[\"output\"], output_format=\"numpyDict\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165efba",
   "metadata": {},
   "source": [
    "## Estimate the redshifts and evaluate performance\n",
    "\n",
    "Now, we estimate our photometric redshifts. We use the [K-Nearest Neighbour algorithm](https://rail-hub.readthedocs.io/en/latest/source/estimators.html#k-nearest-neighbor) to estimate our redshifts, varying the minimum and maximum allowed number of neighbours to see its effect on the final result. To do this, we iterate over a list of the different parameter inputs we want to use for the estimator. In each loop, we:\n",
    "- estimate the redshifts with the chosen parameters\n",
    "- summarize the distribution of redshifts using the Naive Stacking and Point Estimate Histogram methods\n",
    "- evaluate how the estimated redshifts compare to the true redshifts (the original test data set before degradation)\n",
    "- save the evaluation results and summarized distributions to dictionaries so we can access them outside the loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f865a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Iterate over estimating photo-zs using KNN \n",
    "\n",
    "# set up parameters to iterate over and dictionaries to store data\n",
    "nb_params = [(3,7), (2,6), (2,8), (4,9)]\n",
    "eval_dict = {}\n",
    "naive_dict = {}\n",
    "point_est_dict = {}\n",
    "\n",
    "for nb_min, nb_max in nb_params:\n",
    "    # train the informer\n",
    "    inform_knn = ri.estimation.algos.k_nearneigh.k_near_neig_informer(\n",
    "        input=train_data[\"output\"], nondetect_val=np.nan, model=\"bpz.pkl\", hdf5_groupname=\"\", nneigh_min=nb_min, nneigh_max=nb_max\n",
    "    )\n",
    "    # get photo-zs\n",
    "    knn_estimated = ri.estimation.algos.k_nearneigh.k_near_neig_estimator(\n",
    "        input=test_data[\"output\"],\n",
    "        model=inform_knn[\"model\"],\n",
    "        nondetect_val=np.nan,\n",
    "        hdf5_groupname=\"\",\n",
    "    )\n",
    "\n",
    "    ### Evaluate the results \n",
    "    evaluator_stage_dict = dict(\n",
    "        metrics=[\"cdeloss\", \"pit\", \"brier\"],\n",
    "        _random_state=None,\n",
    "        metric_config={\n",
    "            \"brier\": {\"limits\": (0, 3.1)},\n",
    "            \"pit\": {\"tdigest_compression\": 1000},\n",
    "        },\n",
    "    )\n",
    "    truth = test_data_orig\n",
    "\n",
    "    the_eval = ri.evaluation.dist_to_point_evaluator.dist_to_point_evaluator(\n",
    "            input={\"data\": knn_estimated[\"output\"], \"truth\": truth[\"output\"]\n",
    "            },\n",
    "            **evaluator_stage_dict,\n",
    "            hdf5_groupname=\"\",\n",
    "        )\n",
    "    \n",
    "    # put the evaluation results in a dictionary so we have them \n",
    "    eval_dict[(nb_min,nb_max)] = the_eval\n",
    "\n",
    "    # summarize the distributions using point estimate and naive stack summarizers \n",
    "    point_estimate_ens = ri.estimation.algos.point_est_hist.point_est_hist_summarizer(\n",
    "    input=knn_estimated[\"output\"]\n",
    "    )\n",
    "    point_est_dict[(nb_min,nb_max)] = point_estimate_ens\n",
    "    naive_stack_ens = ri.estimation.algos.naive_stack.naive_stack_summarizer(\n",
    "        input=knn_estimated[\"output\"]\n",
    "    )\n",
    "    naive_dict[(nb_min,nb_max)] = naive_stack_ens\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f3f56",
   "metadata": {},
   "source": [
    "## Compare the results\n",
    "\n",
    "We can take a look at the evaluation metrics that we've generated for each of the runs to see how they compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: either make this into a nicer table or just print out the dictionary?\n",
    "results_tables = {\n",
    "    key: tables_io.convertObj(val[\"summary\"], tables_io.types.PD_DATAFRAME)\n",
    "    for key, val in eval_dict.items()\n",
    "}\n",
    "results_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a73606",
   "metadata": {},
   "source": [
    "We can also plot the summarized distributions of all the photometric redshifts generated in a loop against each other, to compare the effect of the different parameters. Below, we plot the runs with the following parameters, since they have the most different evaluation metrics: \n",
    "- minimum neighbours: 3, maximum neighbours: 7\n",
    "- minimum neighbours: 2, maximum neighbours: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of point estimate summarized distribution \n",
    "point_est_dict[(3,7)][\"output\"].plot_native(xlim=(0, 3))\n",
    "point_est_dict[(2,6)][\"output\"].plot_native(xlim=(0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of naive stack summarized distribution \n",
    "naive_dict[(3,7)][\"output\"].plot_native(xlim=(0,3))\n",
    "naive_dict[(2,6)][\"output\"].plot_native(xlim=(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc501ed",
   "metadata": {},
   "source": [
    "## Using multiprocessing\n",
    "\n",
    "Let's say we wanted to do the same as above but with a lot more parameters (and perhaps with a slower algorithm). We can use the python `multiprocessing` module to run the whole loop concurrently, and speed up the process a little. To do this, we need to turn our loop above into its own function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d894deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_photoz(nb_lims):\n",
    "    \"\"\"A function to estimate photo-zs using the KNN alorithm, given a minimum and maximum number of nearest neighbours. It will \n",
    "    then evaluate the performance \"\"\"\n",
    "\n",
    "    # nb_lims, train_data, test_data, inform_knn, test_data_orig = args[0], args[1][0], args[1][1], args[1][2]\n",
    "\n",
    "    # train the informer\n",
    "    inform_knn = ri.estimation.algos.k_nearneigh.k_near_neig_informer(\n",
    "        input=train_data[\"output\"], nondetect_val=np.nan, model=\"bpz.pkl\", hdf5_groupname=\"\", nneigh_min=nb_lims[0], nneigh_max=nb_lims[1]\n",
    "    )\n",
    "    # get photo-zs\n",
    "    knn_estimated = ri.estimation.algos.k_nearneigh.k_near_neig_estimator(\n",
    "        input=test_data[\"output\"],\n",
    "        model=inform_knn[\"model\"],\n",
    "        nondetect_val=np.nan,\n",
    "        hdf5_groupname=\"\",\n",
    "    )\n",
    "   \n",
    "    ### Evaluate the results \n",
    "    evaluator_stage_dict = dict(\n",
    "        metrics=[\"cdeloss\", \"pit\", \"brier\"],\n",
    "        _random_state=None,\n",
    "        metric_config={\n",
    "            \"brier\": {\"limits\": (0, 3.1)},\n",
    "            \"pit\": {\"tdigest_compression\": 1000},\n",
    "        },\n",
    "    )\n",
    "    truth = test_data_orig\n",
    "\n",
    "    the_eval = ri.evaluation.dist_to_point_evaluator.dist_to_point_evaluator(\n",
    "            input={\"data\": knn_estimated[\"output\"], \"truth\": truth[\"output\"]\n",
    "            },\n",
    "            **evaluator_stage_dict,\n",
    "            hdf5_groupname=\"\",\n",
    "        )\n",
    "    \n",
    "    # put the evaluation results in a dictionary so we have them \n",
    "    eval_dict_lg[(nb_lims[0],nb_lims[1])] = the_eval\n",
    "\n",
    "    # summarize the distributions using point estimate and naive stack summarizers \n",
    "    point_estimate_ens = ri.estimation.algos.point_est_hist.point_est_hist_summarizer(\n",
    "    input=knn_estimated[\"output\"]\n",
    "    )\n",
    "    point_est_dict_lg[(nb_lims[0],nb_lims[1])] = point_estimate_ens\n",
    "    naive_stack_ens = ri.estimation.algos.naive_stack.naive_stack_summarizer(\n",
    "        input=knn_estimated[\"output\"]\n",
    "    )\n",
    "    naive_dict_lg[(nb_lims[0],nb_lims[1])] = naive_stack_ens\n",
    "    return the_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88efba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "\n",
    "# set up parameters to iterate over and dictionaries to store data\n",
    "nb_params = [(3,7), (2,6), (2,8), (4,9),(5,10), (1,9), (2,9), (3,10)]\n",
    "nb_mins = [3,2,2,4,5,1,2,3]\n",
    "nb_maxs = [7,6,8,9,10,9,9,10]\n",
    "eval_dict_lg = {}\n",
    "naive_dict_lg = {}\n",
    "point_est_dict_lg = {}\n",
    "\n",
    "pool = Pool(4)\n",
    "for result in pool.imap_unordered(estimate_photoz, nb_params):\n",
    "    print(result )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe9263",
   "metadata": {},
   "source": [
    "### Comparing results\n",
    "\n",
    "Now we can take a look at the dictionary of evaluation metrics, and compare the reuslts for the different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0cbb0",
   "metadata": {},
   "source": [
    "Let's plot the distributinos of two different runs with different evalutation metrics to see what was different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15093bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of naive stack summarized distribution \n",
    "point_est_dict_lg[(3,7)][\"output\"].plot_native(xlim=(0,3))\n",
    "point_est_dict_lg[(5,10)][\"output\"].plot_native(xlim=(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f698163",
   "metadata": {},
   "source": [
    "### Large datasets\n",
    "\n",
    "If the code is slow because you're using extremely large datasets, or you're running into memory issues for the same reason, then we suggest using a pipeline. Pipelines are ideal for large datasets, as the code will chunk up large files and iterate through them as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d25679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
