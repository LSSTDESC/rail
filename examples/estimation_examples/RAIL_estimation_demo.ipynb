{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAIL/Estimation Tutorial Notebook\n",
    "\n",
    "author: Sam Schmidt, Eric Charles, others...\n",
    "\n",
    "last run successfully: August 4, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook demonstrating some of the features of the LSSTDESC `RAIL` package, namely the features of `estimation`.  \n",
    "\n",
    "`RAIL/estimation` is the interface for running production level photo-z codes within DESC.  There is a minimimal superclass that sets up some file paths and variable names, each specific photo-z code resides in a subclass with code-specific setup variables.  More extensive documentation is available on Read the Docs here:\n",
    "https://rail-hub.readthedocs.io/en/latest/\n",
    "\n",
    "The source code for RAIL is available on GitHub at:\n",
    "https://github.com/LSSTDESC/RAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail\n",
    "import qp\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by setting up the Rail data store.  RAIL uses [ceci](https://github.com/LSSTDESC/ceci), which is designed for pipelines rather than interactive notebooks, the data store will work around that and enable us to use data interactively.   Some files will appear in the data store with the prefix \"inprogress_\" as they are stored in memory for use in the notebook, but the data will also be written out to file.  See the `RAIL/examples/goldenspike_examples/goldenspike.ipynb` example notebook for more details on the Data Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all available estimators\n",
    "\n",
    "There is some handy functionality in `rail.stages` to import all available stages that are installed in your environment.  RailStage knows about all of the sub-types of stages.  The are stored in the `RailStage.pipeline_stages` dict.  By looping through the values in that dict we can and asking if each one is a sub-class of `rail.estimation.estimator.CatEstimator` we can identify the available estimators that operator on catalog-like inputs.  Let's run this `import_and_attach_all()` command, and then print out the subclasses that are now available for use (though in this demo we only take advantage of two specific estimators):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail.stages\n",
    "rail.stages.import_and_attach_all()\n",
    "\n",
    "for val in RailStage.pipeline_stages.values():\n",
    "    if issubclass(val[0], rail.estimation.estimator.CatEstimator):\n",
    "        print(val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a list of the available photo-z algorithms, as printed out above.  These are the names of the specific subclasses that invoke a particular method, and currently include:\n",
    "\n",
    "- `BPZliteEstimator` is a template-based code that outputs the posterior estimated given a specific template set and Bayesian prior. See Benitez (2000) for more details.\n",
    "- `CMNNEstimator` is an implementation of the \"colour-matched nearest neighbour` estimator described in [Graham et al 2018](https://ui.adsabs.harvard.edu/abs/2018AJ....155....1G/abstract).  It returns a single Gaussian for each galaxy.\n",
    "- `DelightEstimator` is a hybrid gaussian process/template-based code, see the [Delight](https://github.com/LSSTDESC/Delight) repo for more details.\n",
    "- `FlexZBoostEstimator` is a fully functional photo-z algorithm, implementing the FlexZBoost conditional density estimate method that was used in the PhotoZDC1 paper.  FlexZBoost has been moved to its own GitHub repo, and is available in the [rail_flexzboost](https://github.com/LSSTDESC/rail_flexzboost/) repo.\n",
    "- `GPzEstimator` is a Gaussian Process-based estimator, see [Almosallam et al 2016](https://ui.adsabs.harvard.edu/abs/2016MNRAS.462..726A/abstract) for details on the algorithm.  It currently returns a single Gaussian for each PDF.\n",
    "- `KNearNeighEstimator` is a simple implementation of a weighted k-nearest neighbor photo-z code, it stores each PDF as a weighted sum of Gaussians based on the distance from neighbors in color space.<br>\n",
    "- `PZFlowEstimator` uses the same normalizing flow code [pzflow](https://github.com/jfcrenshaw/pzflow) used in the `creation` module to predict redshift PDFs.\n",
    "- `RandomGaussEstimator` is a very simple class that does not actually predict a meaningful photo-z, instead it produces a randomly drawn Gaussian for each galaxy.\n",
    "- `SklNeurNetEstimator` uses `sklearn`'s neural network to predict a point redshift from the training data, then assigns a sigma width based on the redshift, another toy model example.\n",
    "- `TrainZEstimator` is our \"pathological\" estimator, it makes a PDF from a histogram of the training data and assigns that PDF to every galaxy.\n",
    "\n",
    "\n",
    "Each code should have two specific classes associated with it: one to train/inform using a set of training data, and a second to actually estimate the photo-z PDFs.  These should be imported from the `src/rail/estimation/algos/[name_of_code].py` module. The naming pattern is `[NameOfCode]Estimator` for the estimating class, and `[NameOfCode]Informer` for the training/ingesting class, for example `FlexZBoostEstimator` and  `FlexZBoostInformer`.  \n",
    "\n",
    "The ceci code base will have us using a pattern where we will first run a `make_stage` method for the class in order to set up the ceci infrastructure.  Each `[name]Informer` class will have a function called `inform` that actually performs the training.  Similarly, every `[photoz name]Estimator` class will have an `estimate` function to compute the PDFs.  We will show examples of this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code-specific parameters\n",
    "Each photo-z code will have code-specific parameters necessary to initialize the code.  These values can be input on the command line, or passed in via a dictionary.<br>\n",
    "\n",
    "Let's start with a very simple demonstration using `KNearNeighEstimator`.  `KNearNeighEstimator` is just `sklearn`'s nearest neighbor method run on the training data and set up within the RAIL interface.  It calculates a normalized weight for the K nearest neighbors based on their distance, and makes a PDF as a sum of K Gaussians, each at the redshift of the training galaxy with amplitude based on the distance weight, and a Gaussian width set by the user.  This is a toy model estimator, but it actually performs very well for representative data sets. There are configuration parameters for the names of columns, random seeds, etc... in KNearNeighEstimator, but they are assigned sensible defaults, see the [KNearNeigh code](https://github.com/LSSTDESC/RAIL/blob/eac-dev/rail/estimation/algos/k_nearneigh.py) for more details, but here is a minimal set to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_dict = dict(zmin=0.0, zmax=3.0, nzbins=301, trainfrac=0.75,\n",
    "                sigma_grid_min=0.01, sigma_grid_max=0.07, ngrid_sigma=10,\n",
    "                nneigh_min=3, nneigh_max=7, hdf5_groupname='photometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `trainfrac` sets the amount of training data to use in training the algorithm.  The remaining fraction is used to validate two quantities, the width of the Gaussians used in constructing the PDF, and the number of neighbors used in each PDF.  The CDE Loss is computed on a grid of width and number of neighbors (NN), and the combination of width and NN with the lowest CDE loss is used.  `sigma_grid_min`, `sigma_grid_max`, and `ngrid_sigma` are used to specify the grid of sigma values to test, while `nneigh_min` and `nneigh_max` are the integer values between which we will check the loss.\n",
    "\n",
    "`zmin`, `zmax`, and `nzbins` are used to create a grid on which the CDE Loss is computed when minimizing the loss to find the best values for sigma and number of neighbors to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by training the algorithm, to to this we instantiate a rail object with a call to the base class.\n",
    "\n",
    "If any essential parameters are missing from the parameter dictionary, they will be set to default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.estimation.algos.k_nearneigh import KNearNeighInformer, KNearNeighEstimator\n",
    "pz_train = KNearNeighInformer.make_stage(name='inform_KNN', model='demo_knn.pkl', **knn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load our training data, which is stored in hdf5 format.  We'll load it into the Data Store so that the ceci stages are able to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.core.utils import RAILDIR\n",
    "trainFile = os.path.join(RAILDIR, 'rail/examples_data/testdata/test_dc2_training_9816.hdf5')\n",
    "testFile = os.path.join(RAILDIR, 'rail/examples_data/testdata/test_dc2_validation_9816.hdf5')\n",
    "training_data = DS.read_file(\"training_data\", TableHandle, trainFile)\n",
    "test_data = DS.read_file(\"test_data\", TableHandle, testFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to train the KDTree, which is done with the `inform` function present in every RAIL/estimation code. The parameter `model` is the name that the trained model object will be saved as in pickle format, in this case `demo_knn.pkl`.  In the future, rather than re-run a potentially time consuming training set, we can simply load this pickle file before we run the estimate stage.\n",
    "\n",
    "KNearNeighEstimator.inform finds the best sigma and NNeigh and stores those along with the KDTree in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pz_train.inform(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now set up the main photo-z stage and run our algorithm on the data to produce simple photo-z estimates.  Note that we are loading the trained model that we computed from the inform stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz = KNearNeighEstimator.make_stage(name='KNN', hdf5_groupname='photometry',\n",
    "                              model=pz_train.get_handle('model'))\n",
    "results = pz.estimate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output file is a qp Ensemble containing the redshift PDFs.  The Ensemble also includes the modes of the PDFs.  The modes are stored in the \"ancillary\" data within qp.  By default it will be in an 1xM array, so you may need to include a `.flatten()` to flatten the array.  The zmode values in the ancillary data can be accessed via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmode = results().ancil['zmode'].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the redshift mode against the true redshifts to see how they look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(test_data()['photometry']['redshift'],zmode,s=1,c='k',label='simple NN mode')\n",
    "plt.plot([0,3],[0,3],'r--');\n",
    "plt.xlabel(\"true redshift\")\n",
    "plt.ylabel(\"simple NN photo-z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, given our very simple estimator.  For the PDFs, KNearNeighEstimator is storing a mixture model parameterization where the PDF is represented by a set of N Gaussians for each galaxy.  As qp Ensembles are built upon scipy.stats infrastructure, we can evaluate the PDF on a set of grid points with the built-in `.pdf` method.  Let's pick a single galaxy from our sample, evaluate the PDF, and plot, along with the value of the mode and the true redshift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zgrid = np.linspace(0, 3., 301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galid = 9529\n",
    "single_gal = np.squeeze(results()[galid].pdf(zgrid))\n",
    "single_zmode = zmode[galid]\n",
    "truez = test_data()['photometry']['redshift'][galid]\n",
    "plt.plot(zgrid,single_gal,color='k',label='single pdf')\n",
    "plt.axvline(single_zmode,color='k', ls='--', label='mode')\n",
    "plt.axvline(truez,color='r',label='true redshift')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"redshift\")\n",
    "plt.ylabel(\"p(z)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that KNearNeigh PDFs do consist of a number of discrete Gaussians, and many have quite a bit of substructure.  This is a naive estimator, and some of these feature are likely spurious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlexZBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That illustrates the basics, now let's try the `FlexZBoostEstimator` estimator.  FlexZBoost has been moved out of the \"base\" RAIL repo, and is available in the [rail_flexzboost](https://github.com/LSSTDESC/rail_flexzboost/) repo.  You can install by cloning that repo and installing directly, or you can install it via PyPI by simply running the command\n",
    "\n",
    "`pip install pz-rail-flexzboost`\n",
    "\n",
    "on the command line.  Once installed, it will function the same as any of the other estimators included in the main RAIL repo.\n",
    "\n",
    "`FlexZBoostEstimator` finds a conditional density estimate for each PDF via a set of weights for basis functions.  This can save space relative to a gridded parameterization, but it also sometimes leads to residual \"bumps\" in the PDF from the underlying parameterization.  For this reason, `FlexZBoostEstimator` has a post-processing stage where it \"trims\" (i.e. sets to zero) any \"bumps\" below a certain threshold.\n",
    "\n",
    "One of the dominant features seen in our PhotoZDC1 analysis of multiple photo-z codes (Schmidt, Malz et al. 2020) was that photo-z estimates were often, in general, overconfident or underconfident in their overall uncertainty in PDFs.  To remedy this, `FlexZBoostEstimator` has an additional post-processing step where it estimates a \"sharpening\" parameter that modulates the width of the PDFs.\n",
    "\n",
    "A portion of the training data is held in reserve to find best-fit values for both `bump_thresh` and `sharpening`, which we find by simply calculating the CDE loss for a grid of `bump_thresh` and `sharpening` values, though once those values are set FlexZBoost will re-train its density estimate model with the full dataset.\n",
    "\n",
    "We'll start with a dictionary of setup parameters for FlexZBoostEstimator, just as we had for the k-nearest neighbor estimator.  Some of the parameters are the same as in k-nearest neighbor above, `zmin`, `zmax`, `nzbins`.  However, FlexZBoostEstimator performs a more in depth training than simpleNN, and as such has more input parameters to control behavior.  These parameters are:\n",
    "\n",
    "- `basis_system`: which basis system to use in the density estimate. The default is `cosine` but `fourier` is also an option\n",
    "- `max_basis`: the maximum number of basis functions parameters to use for PDFs\n",
    "- `regression_params`: a dictionary of options fed to `xgboost` that control the maximum depth and the `objective` function.  An update in `xgboost` means that `objective` should now be set to `reg:squarederror` for proper functioning.\n",
    "- `trainfrac`: The fraction of the training data to use for training the density estimate.  The remaining galaxies will be used for validation of `bump_thresh` and `sharpening`.\n",
    "- `bumpmin`: the minimum value to test in the `bump_thresh` grid\n",
    "- `bumpmax`: the maximum value to test in the `bump_thresh` grid\n",
    "- `nbump`: how many points to test in the `bump_thresh` grid\n",
    "- `sharpmin`, `sharpmax`, `nsharp`: same as equivalent `bump_thresh` params, but for `sharpening` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz_dict = dict(zmin=0.0, zmax=3.0, nzbins=301,\n",
    "               trainfrac=0.75, bumpmin=0.02, bumpmax=0.35,\n",
    "               nbump=20, sharpmin=0.7, sharpmax=2.1, nsharp=15,\n",
    "               max_basis=35, basis_system='cosine',\n",
    "               hdf5_groupname='photometry',\n",
    "               regression_params={'max_depth': 8,'objective':'reg:squarederror'})\n",
    "fz_modelfile = 'demo_FZB_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.estimation.algos.flexzboost import FlexZBoostInformer, FlexZBoostEstimator\n",
    "inform_pzflex = FlexZBoostInformer.make_stage(name='inform_fzboost', model=fz_modelfile, **fz_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this data to train our model using the `FlexZBoostInformer`.  `FlexZBoost` uses xgboost to determine a conditional density estimate model, and also fits a `bump_thresh` parameter that erases small peaks that are an artifact of the `cosine` parameterization.  It then finds a best fit `sharpen` parameter that modulates the peaks with a power law.\n",
    "\n",
    "`FlexZBoost` is a bit more sophisticated than the earlier k-nearest neighbor estimator, so it will take a bit longer to train, but not drastically so.  We specified the name of the model file, `demo_FZB_model.pkl`, which will store our trained model for use with the estimation stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inform_pzflex.inform(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took slightly longer to train, but still under a minute on a semi-new laptop.  If we have an existing pretrained model, for example the one in the file `demo_FZB_model.pkl` we can skip this step in subsequent runs of estimate: that is, we load this pickled model without having to repeat the training stage for this specific training data, and that can save time for larger training sets that would take longer to create the model.\n",
    "\n",
    "There are two supported model output representations, `interp` (default) and `flexzboost`. Using `interp` will store the output as interpolated y values for a given set of x values, using this approach will require moderately more storage space, but will generally be faster to work with. Using `flexzboost` will store the output weights from Flexcode. This results in a smaller storage size on disk, but will also require additional computation time when working with the results. \n",
    "\n",
    "For additional comparisons of the approaches, see the documentation for `qp_flexzboost` here: https://qp-flexzboost.readthedocs.io/en/latest/source/performance_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pzflex = FlexZBoostEstimator.make_stage(name='fzboost', hdf5_groupname='photometry',\n",
    "                            model=inform_pzflex.get_handle('model'))\n",
    "\n",
    "# For this notebook, we will use the default value of qp_representation as shown\n",
    "# above due to the additional computation time that would be required in the\n",
    "# later steps when working with the flexzboost representation.\n",
    "# Below are two examples showing the explicit use of the qp_representation argument.\n",
    "\"\"\"\n",
    "pzflex = FlexZBoostEstimator.make_stage(name='fzboost', hdf5_groupname='photometry',\n",
    "                            model=inform_pzflex.get_handle('model'),\n",
    "                            qp_representation='interp')\n",
    "\n",
    "pzflex = FlexZBoostEstimator.make_stage(name='fzboost', hdf5_groupname='photometry',\n",
    "                            model=inform_pzflex.get_handle('model'),\n",
    "                            qp_representation='flexzboost')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, only a few seconds.  So, if you are running an algorithm with a burdensome training requirement, saving a trained copy of the model for later repeated use can be a real time saver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute photo-z's using with the `estimate` method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fzresults = pzflex.estimate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the median and mode values of the PDFs and plot their distribution (the modes are already stored in the ancillary data, but here is an example of computing via qp as well):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz_medians = fzresults().median()\n",
    "fz_modes = fzresults().mode(grid=zgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fz_medians, bins=np.linspace(-.005,3.005,101));\n",
    "plt.xlabel(\"redshift\")\n",
    "plt.ylabel(\"Number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot an example PDF from the results file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galid = 9529\n",
    "single_gal = np.squeeze(fzresults()[galid].pdf(zgrid))\n",
    "single_zmedian = fz_medians[galid]\n",
    "truez = test_data()['photometry']['redshift'][galid]\n",
    "plt.plot(zgrid,single_gal,color='k',label='single pdf')\n",
    "plt.axvline(single_zmedian,color='k', ls='--', label='median')\n",
    "plt.axvline(truez,color='r',label='true redshift')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"redshift\")\n",
    "plt.ylabel(\"p(z)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot a few point estimates to make sure our algorithm worked properly, we can compute the median of the PDF trivially and plot against true redshift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(test_data()['photometry']['redshift'],fz_modes,s=1,c='k')\n",
    "plt.plot([0,3],[0,3],'r--')\n",
    "plt.xlabel(\"true redshift\")\n",
    "plt.ylabel(\"photoz mode\")\n",
    "plt.title(\"median point estimate for FlexZBoost\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look very good! FlexZBoost is a mature algorithm, and with representative training data we see a very tight correlation with true redshift and few outliers.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
