{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a40421-e7b3-4a7d-9a97-b70bf6cb8f28",
   "metadata": {},
   "source": [
    "# GPz Estimation Example\n",
    "\n",
    "**Author:** Sam Schmidt\n",
    "\n",
    "**Last Run Successfully:** September 26, 2023\n",
    "\n",
    "A quick demo of running GPz on the typical test data.  You should have installed rail_gpz_v1 (we highly recommend that you do this from within a custom conda environment so that all dependencies for package versions are met), either by cloning and installing from github, or with:\n",
    "```\n",
    "pip install pz-rail-gpz-v1\n",
    "```\n",
    "\n",
    "As RAIL is a namespace package, installing rail_gpz_v1 will make `GPzInformer` and `GPzEstimator` available, and they can be imported via:<br>\n",
    "```\n",
    "from rail.estimation.algos.gpz import GPzInformer, GPzEstimator\n",
    "```\n",
    "\n",
    "Let's start with all of our necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e5adf-9e8f-496b-808d-83225c34a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rail\n",
    "import qp\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.estimation.algos.gpz import GPzInformer, GPzEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf96656-7cdc-4d45-ba13-355e3386e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the DataStore to keep track of data\n",
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b2b33-c93b-41b8-b3be-a526418f0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_rail_file is a convenience function that finds a file in the RAIL ecosystem   We have several example data files that are copied with RAIL that we can use for our example run, let's grab those files, one for training/validation, and the other for testing:\n",
    "from rail.core.utils import find_rail_file\n",
    "trainFile = find_rail_file('examples_data/testdata/test_dc2_training_9816.hdf5')\n",
    "testFile = find_rail_file('examples_data/testdata/test_dc2_validation_9816.hdf5')\n",
    "training_data = DS.read_file(\"training_data\", TableHandle, trainFile)\n",
    "test_data = DS.read_file(\"test_data\", TableHandle, testFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cfd420-a6cd-4f1d-a54b-536d95aac703",
   "metadata": {},
   "source": [
    "Now, we need to set up the stage that will run GPz.  We begin by defining a dictionary with the config options for the algorithm.  There are sensible defaults set, we will override several of these as an example of how to do this.  Config parameters not set in the dictionary will automatically be set to their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44825971-2974-4dde-a072-c774655b22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpz_train_dict = dict(n_basis=60, trainfrac=0.8, csl_method=\"normal\", max_iter=150, hdf5_groupname=\"photometry\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd5df8-7449-4a2f-a4f8-7ec18eae92d4",
   "metadata": {},
   "source": [
    "Let's set up the training stage.  We need to provide a name for the stage for ceci, as well as a name for the model file that will be written by the stage.  We also include the arguments in the dictionary we wrote above as additional arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee70194-46d5-4b3a-a282-b7ca123d008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the stage to run our GPZ_training\n",
    "pz_train = GPzInformer.make_stage(name=\"GPz_Train\", model=\"GPz_model.pkl\", **gpz_train_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cceb899-0acb-448d-8a58-7a61227547a9",
   "metadata": {},
   "source": [
    "We are now ready to run the stage to create the model.  We will use the training data from `test_dc2_training_9816.hdf5`, which contains 10,225 galaxies drawn from healpix 9816 from the cosmoDC2_v1.1.4 dataset, to train the model.  Note that we read this data in called `train_data` in the DataStore.  Note that we set `trainfrac` to 0.8, so 80% of the data will be used in the \"main\" training, but 20% will be reserved by `GPzInformer` to determine a SIGMA parameter.  We set `max_iter` to 150, so we will see 150 steps where the stage tries to maximize the likelihood. We run the stage as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d925f67e-d3a5-49ae-9a1e-6ac043dbdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pz_train.inform(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c7a409-1919-49c6-a258-4af05fe30e00",
   "metadata": {},
   "source": [
    "This should have taken about 30 seconds on a typical desktop computer, and you should now see a file called `GPz_model.pkl` in the directory.  This model file is used by the `GPzEstimator` stage to determine our redshift PDFs for the test set of galaxies.  Let's set up that stage, again defining a dictionary of variables for the config params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a9632-adfd-42cc-96c7-c0bb34390b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpz_test_dict = dict(hdf5_groupname=\"photometry\", model=\"GPz_model.pkl\")\n",
    "\n",
    "gpz_run = GPzEstimator.make_stage(name=\"gpz_run\", **gpz_test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe0f11-5c38-4856-b845-d5fb830e707a",
   "metadata": {},
   "source": [
    "Let's run the stage and compute photo-z's for our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c739a8-1155-4265-ba2b-45709399f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = gpz_run.estimate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d2a56-029b-45d2-b5e1-10eee75d24bb",
   "metadata": {},
   "source": [
    "This should be very fast, under a second for our 20,449 galaxies in the test set.  Now, let's plot a scatter plot of the point estimates, as well as a few example PDFs.  We can get access to the `qp` ensemble that was written via the DataStore via `results()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8dc61f-c073-44b1-9d32-6e5d715e699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa61f3d-426e-41d0-9d3f-65eb05a5b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "expdfids = [2, 180, 13517, 18032]\n",
    "fig, axs = plt.subplots(4, 1, figsize=(12,10))\n",
    "for i, xx in enumerate(expdfids):\n",
    "    axs[i].set_xlim(0,3)\n",
    "    ens[xx].plot_native(axes=axs[i])\n",
    "axs[3].set_xlabel(\"redshift\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093dd6f9-f935-4aa5-9898-1c52b3bef6d1",
   "metadata": {},
   "source": [
    "GPzEstimator parameterizes each PDF as a single Gaussian, here we see a few examples of Gaussians of different widths.  Now let's grab the mode of each PDF (stored as ancil data in the ensemble) and compare to the true redshifts from the test_data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ac16a-1c2b-4be8-a947-362bcc039431",
   "metadata": {},
   "outputs": [],
   "source": [
    "truez = test_data.data['photometry']['redshift']\n",
    "zmode = ens.ancil['zmode'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f63f2e-7931-41c5-8cec-32a60230d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(truez, zmode, s=3)\n",
    "plt.plot([0,3],[0,3], 'k--')\n",
    "plt.xlabel(\"redshift\", fontsize=12)\n",
    "plt.ylabel(\"z mode\", fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
