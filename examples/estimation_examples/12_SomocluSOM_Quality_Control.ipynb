{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48660fd",
   "metadata": {},
   "source": [
    "# SOMocluSummarizer+Quality Control demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83f923",
   "metadata": {},
   "source": [
    "Author: Ziang Yan <br>\n",
    "Last successfully run: Nov 22, 2024<br>\n",
    "\n",
    "This notebook creats an end-to-end example for the SOM summarizer PLUS quality controld defined in https://arxiv.org/pdf/2007.15635. Including:\n",
    "\n",
    "1) create photometric realizations for a training and spectroscopic sample;\n",
    "2) measuring BPZ for the training and spectroscopic samples;\n",
    "3) make the same tomographic cut on the training and spec samples;\n",
    "4) informing a `rail_som` model with the training sample and summarizing it with the spec sample;\n",
    "5) performing two quality control (arXiv: 1909.09632);\n",
    "6) summarizing the goodness of redshift calibration and compare between QCs;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b187a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pickle\n",
    "import rail\n",
    "import os\n",
    "import qp\n",
    "from rail.core.utils import RAILDIR\n",
    "\n",
    "import tables_io\n",
    "from rail.core.data import TableHandle, ModelHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.estimation.algos.somoclu_som import SOMocluInformer, SOMocluSummarizer\n",
    "from rail.estimation.algos.somoclu_som import get_bmus, plot_som"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1e4dc",
   "metadata": {},
   "source": [
    "Next, let's set up the Data Store, so that our RAIL module will know where to fetch data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8c14b",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, let's grab some data files.  For the SOM, we will want to train on a fairly large, representative set that encompasses all of our expected data.  We'll grab a larger data file than we typically use in our demos to ensure that we construct a meaningful SOM.\n",
    "\n",
    "## Run this command on the command line to get the larger data file to train the SOM:\n",
    "`curl -O https://portal.nersc.gov/cfs/lsst/schmidt9/healpix_10326_bright_data.hdf5`\n",
    "\n",
    "and then move the resulting file to this directory, i.e. RAIL/examples/estimation.  This data consists of ~150,000 galaxies from a single healpix pixel of the comsoDC2 truth catalog with mock 10-year magnitude errors added.  It is cut at a relatively bright i<23.5 magnitudes in order to concentrate on galaxies with particularly high S/N rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40276b32",
   "metadata": {},
   "source": [
    "# First read the target and spec catalogue from a pre-trained pzflow stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"./healpix_10326_bright_data.hdf5\"\n",
    "\n",
    "if not os.path.exists(training_file):\n",
    "  os.system('curl -O https://portal.nersc.gov/cfs/lsst/PZ/healpix_10326_bright_data.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34082c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = DS.read_file(\"training_data\", TableHandle, training_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ee4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmask = (training_data.data['photometry']['mag_i_lsst'] <23.5)\n",
    "trim_test = {}\n",
    "for key in training_data.data['photometry'].keys():\n",
    "    trim_test[key] = training_data.data['photometry'][key][pmask]\n",
    "trim_dict = dict(photometry=trim_test)\n",
    "target_data_all = DS.add_data(\"target_data_raw\", trim_dict, TableHandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.utils.path_utils import find_rail_file\n",
    "\n",
    "specfile = find_rail_file(\"examples_data/testdata/test_dc2_validation_9816.hdf5\")\n",
    "ref_data_raw = tables_io.read(specfile)['photometry']\n",
    "smask = (ref_data_raw['mag_i_lsst'] <23.5)\n",
    "trim_spec = {}\n",
    "for key in ref_data_raw.keys():\n",
    "    trim_spec[key] = ref_data_raw[key][smask]\n",
    "trim_dict = dict(photometry=trim_spec)\n",
    "ref_data_all = DS.add_data(\"ref_data_raw\", trim_dict, TableHandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e1c55",
   "metadata": {},
   "source": [
    "# Now measure the photometric redshifts using the `bpz_lite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb36086",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "lsst_bands = []\n",
    "lsst_errs = []\n",
    "lsst_filts = []\n",
    "for band in bands:\n",
    "    lsst_bands.append(f\"mag_{band}_lsst\")\n",
    "    lsst_errs.append(f\"mag_err_{band}_lsst\")\n",
    "    lsst_filts.append(f\"DC2LSST_{band}\")\n",
    "print(lsst_bands)\n",
    "print(lsst_filts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e264ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.core.utils import RAILDIR\n",
    "import os\n",
    "from rail.core.utils import RAILDIR\n",
    "from rail.estimation.algos.bpz_lite import BPZliteInformer, BPZliteEstimator\n",
    "from rail.core.data import ModelHandle\n",
    "custom_data_path = RAILDIR + '/rail/examples_data/estimation_data/data'\n",
    "\n",
    "hdfnfile = os.path.join(RAILDIR, \"rail/examples_data/estimation_data/data/CWW_HDFN_prior.pkl\")\n",
    "sedfile = os.path.join(RAILDIR, \"rail/examples_data/estimation_data/data/SED/COSMOS_seds.list\")\n",
    "\n",
    "with open(hdfnfile, \"rb\") as f:\n",
    "    hdfnmodel = pickle.load(f)\n",
    "\n",
    "custom_dict_phot = dict(hdf5_groupname=\"photometry\",\n",
    "                   output=\"bpz_results_phot_qc.hdf5\", \n",
    "                   bands=lsst_bands, \n",
    "                   err_bands=lsst_errs,\n",
    "                   filter_list=lsst_filts,\n",
    "                   prior_band='mag_i_lsst',spectra_file=sedfile,\n",
    "                   data_path=custom_data_path,\n",
    "                   no_prior=False)\n",
    "\n",
    "custom_dict_spec = dict(hdf5_groupname=\"photometry\",\n",
    "                   output=\"bpz_results_spec_qc.hdf5\", \n",
    "                    bands=lsst_bands, \n",
    "                   err_bands=lsst_errs,\n",
    "                   filter_list=lsst_filts,\n",
    "                   prior_band='mag_i_lsst',spectra_file=sedfile,\n",
    "                   data_path=custom_data_path,\n",
    "                   no_prior=False)\n",
    "\n",
    "cosmospriorfile = os.path.join(RAILDIR, \"rail/examples_data/estimation_data/data/COSMOS31_HDFN_prior.pkl\")\n",
    "cosmosprior = DS.read_file(\"cosmos_prior\", ModelHandle, cosmospriorfile)\n",
    "\n",
    "phot_run = BPZliteEstimator.make_stage(name=\"rerun_bpz_phot\", model=cosmosprior, **custom_dict_phot)\n",
    "spec_run = BPZliteEstimator.make_stage(name=\"rerun_bpz_spec\", model=cosmosprior, **custom_dict_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "phot_run.estimate(target_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb67aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_run.estimate(ref_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092295bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_bpz_file = 'bpz_results_phot_qc.hdf5'\n",
    "bpz_phot_all = tables_io.read(phot_bpz_file)['ancil']['zmode']\n",
    "\n",
    "spec_bpz_file = 'bpz_results_spec_qc.hdf5'\n",
    "bpz_spec_all = tables_io.read(spec_bpz_file)['ancil']['zmode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ff0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(target_data_all.data['photometry']['redshift'], bpz_phot_all, s=0.3)\n",
    "plt.plot(target_data_all.data['photometry']['redshift'],target_data_all.data['photometry']['redshift'], color='C1')\n",
    "plt.title('Test data')\n",
    "plt.xlabel(r'$Z_{\\mathrm{spec}}$', fontsize=15)\n",
    "plt.ylabel(r'$Z_{\\mathrm{phot}}$', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63834d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(ref_data_all.data['photometry']['redshift'], bpz_spec_all, s=0.3)\n",
    "plt.plot(ref_data_all.data['photometry']['redshift'],ref_data_all.data['photometry']['redshift'], color='C1')\n",
    "plt.title('Spec data')\n",
    "plt.xlabel(r'$Z_{\\mathrm{spec}}$', fontsize=15)\n",
    "plt.ylabel(r'$Z_{\\mathrm{phot}}$', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb12ee",
   "metadata": {},
   "source": [
    "## cut the data to make a tomographic bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_low = 0.2\n",
    "bin_high = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_data_test = {}\n",
    "\n",
    "mask_phot = ((bpz_phot_all > bin_low) & (bpz_phot_all < bin_high))\n",
    "mask_phot &= (target_data_all.data['photometry']['redshift'] > 0)\n",
    "\n",
    "bpz_phot = bpz_phot_all[mask_phot]\n",
    "\n",
    "for key in target_data_all.data['photometry'].keys():\n",
    "    trim_data_test[key] = target_data_all.data['photometry'][key][mask_phot]\n",
    "trimdict_test = dict(photometry=trim_data_test)\n",
    "target_data = DS.add_data(\"testing_data\", trimdict_test, TableHandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_data_spec = {}\n",
    "\n",
    "mask_spec = ((bpz_spec_all > bin_low) & (bpz_spec_all<bin_high))\n",
    "mask_spec &= (ref_data_all.data['photometry']['redshift'] > 0)\n",
    "\n",
    "bpz_spec = bpz_spec_all[mask_spec]\n",
    "\n",
    "for key in target_data_all.data['photometry'].keys():\n",
    "    trim_data_spec[key] = ref_data_all.data['photometry'][key][mask_spec]\n",
    "trimdict_spec = dict(photometry=trim_data_spec)\n",
    "ref_data = DS.add_data(\"ref_data\", trimdict_spec, TableHandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Redshift distributions')\n",
    "plt.xlabel(r'$Z_{\\mathrm{spec}}$')\n",
    "plt.ylabel('dN/dz')\n",
    "\n",
    "plt.hist(target_data.data['photometry']['redshift'], bins=50, density=True, histtype='step', label='Target')\n",
    "plt.hist(ref_data.data['photometry']['redshift'], bins=50, density=True, histtype='step', label='Reference')\n",
    "plt.axvline(bin_low, color='k', linestyle='--')\n",
    "plt.axvline(bin_high, color='k', linestyle='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b6896c",
   "metadata": {},
   "source": [
    "# Now let's train a SOM with the color from the target set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51251f2d",
   "metadata": {},
   "source": [
    "We need to define all of our necessary initialization params, which includes the following:\n",
    "- `name` (str): the name of our estimator, as utilized by ceci\n",
    "- `model` (str): the name for the model file containing the SOM and associated parameters that will be written by this stage\n",
    "- `hdf5_groupname` (str): name of the hdf5 group (if any) where the photometric data resides in the training file\n",
    "- `n_rows` (int): the number of dimensions in the y-direction for our 2D SOM\n",
    "- `n_columns` (int): the number of dimensions in the x-direction for our 2D SOM\n",
    "- `gridtype` (str): the parameter that specifies the grid form of the nodes. Options: `rectangular`(default) and `hexagonal`.\n",
    "- `initialization` (str): the parameter specifying the method of initializing the SOM. Options: `pca`: principal componant analysis (default); `random`: randomly initialize the SOM.\n",
    "- `maptype` (str): the parameter specifying the map topology. Options: `planar`(default) and `toroid`.\n",
    "- `n_epochs` (int): the number of iteration steps during SOM training.  SOMs can take a while to converge, so we will use a fairly large number of 500,000 iterations.\n",
    "- `std_coeff` (float): the \"radius\" of how far to spread changes in the SOM \n",
    "- `som_learning_rate` (float): a number between 0 and 1 that controls how quickly the weighting function decreases.  SOM's are not guaranteed to converge mathematically, and so this parameter tunes how the response drops per iteration.  A typical values we might use might be between 0.5 and 0.75.\n",
    "- `column_usage` (str):  this value determines what values will be used to construct the SOM, valid choices are `colors`, `magandcolors`, and `columns`.  If set to `colors`, the code will take adjacent columns as specified in `usecols` to construct colors and use those as SOM inputs.  If set to `magandcolors` it will use the single column specfied by `ref_column_name` and the aforementioned colors to construct the SOM.  If set to `columns` then it will simply take each of the columns in `usecols` with no modification.  So, if a user wants to use K magnitudes and L colors, they can precompute the colors and specify all names in `usecols`.  NOTE: accompanying `usecols` you must have a `nondetect_val` dictionary that lists the replacement values for any non-detection-valued entries for each column, see the code for an example dictionary.  WE will set `column_usage` to colors and use only colors in this example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60262b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 101\n",
    "grid_type = 'hexagonal'\n",
    "\n",
    "\n",
    "inform_dict = dict(model='output_SOMoclu_model.pkl', \n",
    "                   hdf5_groupname='photometry',\n",
    "                   n_rows=dim, n_columns=dim, \n",
    "                   gridtype = grid_type,\n",
    "                   maptype = 'toroid',\n",
    "                   n_epochs=30,\n",
    "                   std_coeff=12.0, som_learning_rate=0.75,\n",
    "                   column_usage='colors')\n",
    "\n",
    "inform_som = SOMocluInformer.make_stage(name='inform_som', **inform_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb09e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inform_som.inform(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587dc808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cont_hist(data, bins):\n",
    "    hist, bin_edge = np.histogram(data, bins=bins, density=True)\n",
    "    return hist, (bin_edge[1:]+bin_edge[:-1])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7867b",
   "metadata": {},
   "source": [
    "# Summarize the SOM with target data and spectroscopic reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "n_clusters = 1000\n",
    "\n",
    "summ_dict = dict(model=\"output_SOMoclu_model.pkl\", hdf5_groupname='photometry',\n",
    "                 spec_groupname='photometry', nzbins=101, nsamples=25,\n",
    "                 output='SOM_ensemble.hdf5', single_NZ='fiducial_SOMoclu_NZ.hdf5',\n",
    "                 n_clusters=n_clusters,\n",
    "                 uncovered_cluster_file ='all_uncovered_cells.hdf5',\n",
    "                 objid_name='id',\n",
    "                 cellid_output='output_cellIDs.hdf5')\n",
    "\n",
    "som_summarizer = SOMocluSummarizer.make_stage(name='SOMoclu_summarizer', aliases=dict(model=\"model_somoclu__\"), **summ_dict)\n",
    "som_summarizer.summarize(target_data, ref_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d773c",
   "metadata": {},
   "source": [
    "We can calculate the best SOM cell using the get_bmus() function defined in somocluSOM.py, which will return the 2D SOM coordinates for each galaxy. Then we group the SOM cells into hierarchical clusters and calculate the occupation and mean redshift in each cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f05fa8b",
   "metadata": {},
   "source": [
    "To do this, we first get the colors for the reference and target sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y']\n",
    "bandnames = [f\"mag_{band}_lsst\" for band in bands]\n",
    "\n",
    "ngal_ref = len(ref_data.data['photometry']['mag_i_lsst'])\n",
    "ngal_target = len(target_data.data['photometry']['mag_i_lsst'])\n",
    "\n",
    "ref_colors = np.zeros([5, ngal_ref])\n",
    "target_colors = np.zeros([5, ngal_target])\n",
    "for i in range(5):\n",
    "\n",
    "    ref_colors[i] = ref_data.data['photometry'][bandnames[i]] - ref_data.data['photometry'][bandnames[i+1]]\n",
    "    target_colors[i] = target_data.data['photometry'][bandnames[i]] - target_data.data['photometry'][bandnames[i+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5862c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output_SOMoclu_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c158e62",
   "metadata": {},
   "source": [
    "Now we call the `get_bmus` function to get the best matching units for the reference and target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d876b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOM = model['som']\n",
    "ref_bmu_coordinates = get_bmus(SOM, ref_colors.T, 1000).T\n",
    "target_bmu_coordinates = get_bmus(SOM, target_colors.T, 1000).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35568326",
   "metadata": {},
   "source": [
    "Find the cluster index for each galaxy in the reference and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0174a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster as sc\n",
    "\n",
    "algorithm = sc.AgglomerativeClustering(n_clusters=n_clusters, linkage='complete')\n",
    "SOM.cluster(algorithm)\n",
    "som_cluster_inds = SOM.clusters.reshape(-1)\n",
    "\n",
    "ref_pixel_coords = np.ravel_multi_index(ref_bmu_coordinates, (dim, dim))\n",
    "ref_som_clusterind = som_cluster_inds[ref_pixel_coords]\n",
    "\n",
    "target_pixel_coords = np.ravel_multi_index(target_bmu_coordinates, (dim, dim))\n",
    "target_som_clusterind = som_cluster_inds[target_pixel_coords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce7000",
   "metadata": {},
   "source": [
    "The next cell defines some functions to plot cluster boundaries on a SOM grid. This function will be added to rail_som in a subsequent update. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac40ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_boundaries(ax, SOM, n_clusters, cluster_inds=None, topology='hexagonal'):\n",
    "    dim = SOM.codebook.shape[0]\n",
    "    som_cluster_ind = SOM.clusters.reshape(-1)\n",
    "    som_centers = find_cell_centers(dim, topology=topology)\n",
    "    som_centers_l = np.array([som_centers.T[0]-dim*1, som_centers.T[1]]).T\n",
    "    som_centers_r = np.array([som_centers.T[0]+dim*1, som_centers.T[1]]).T\n",
    "    som_centers_u = np.array([som_centers.T[0], som_centers.T[1]+dim*np.sqrt(3)/2]).T\n",
    "    som_centers_b = np.array([som_centers.T[0], som_centers.T[1]-dim*np.sqrt(3)/2]).T\n",
    "    if cluster_inds is None:\n",
    "        cluster_inds = np.arange(n_clusters)\n",
    "    for i in (cluster_inds):\n",
    "        centers = (np.vstack([som_centers[np.where(som_cluster_ind==i)[0]],\n",
    "                         som_centers_l[np.where(som_cluster_ind==i)[0]], som_centers_u[np.where(som_cluster_ind==i)[0]], \n",
    "                         som_centers_r[np.where(som_cluster_ind==i)[0]], som_centers_b[np.where(som_cluster_ind==i)[0]]]))\n",
    "        linep = get_manycells_boundary(centers, topology='hexagonal')\n",
    "        for points in linep:\n",
    "            if points.T[0].min() < som_centers.T[0].min()-1 or points.T[0].max() > som_centers.T[0].max()+1 or points.T[1].min() < som_centers.T[1].min()-np.sqrt(3)/2 or points.T[1].max() > som_centers.T[1].max()+np.sqrt(3)/2:\n",
    "            #plt.plot(points.T[0], points.T[1], color='blue')\n",
    "                continue\n",
    "            ax.plot(points.T[0], points.T[1], color='k', lw=0.2)\n",
    "    return\n",
    "\n",
    "def find_cell_centers(dim, topology='rectangular'):\n",
    "    if topology == 'rectangular':\n",
    "        x = np.arange(dim) + 0.5\n",
    "        y = np.arange(dim) + 0.5\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        xx = xx.reshape(-1)\n",
    "        yy = yy.reshape(-1)\n",
    "        centers = np.array([xx, yy]).T\n",
    "    if topology == 'hexagonal':\n",
    "        yy, xx= np.meshgrid(np.arange(dim), np.arange(dim))\n",
    "        shift = np.zeros(dim)\n",
    "        shift[::2]=-0.5\n",
    "        xx = xx + shift\n",
    "        yy = yy * (np.sqrt(3) / 2)\n",
    "        centers = np.array([xx.reshape(-1), yy.reshape(-1)]).T\n",
    "    return centers\n",
    "\n",
    "def get_cell_boundary(center, topology='rectangular'):\n",
    "    if topology == 'rectangular':\n",
    "        points = [np.array([[center[0]-0.5, center[1]-0.5], [center[0]-0.5, center[1]+0.5]]),\n",
    "                 np.array([[center[0]-0.5, center[1]+0.5], [center[0]+0.5, center[1]+0.5]]),\n",
    "                np.array([[center[0]+0.5, center[1]-0.5], [center[0]+0.5, center[1]+0.5]]),\n",
    "                 np.array([[center[0]-0.5, center[1]-0.5], [center[0]+0.5, center[1]-0.5]])]\n",
    "        return points\n",
    "    elif topology == 'hexagonal':\n",
    "        dx = 0.5\n",
    "        dy = np.sqrt(3)/6\n",
    "        points = [np.array([[center[0]-dx, center[1]+dy], [center[0], center[1]+2*dy]]),\n",
    "                  np.array([[center[0], center[1]+2*dy], [center[0]+dx, center[1]+dy]]),\n",
    "                 np.array([[center[0]+dx, center[1]-dy], [center[0]+dx, center[1]+dy]]),\n",
    "                 np.array([[center[0], center[1]-2*dy], [center[0]+dx, center[1]-dy]]),\n",
    "                 np.array([[center[0]-dx, center[1]-dy], [center[0], center[1]-2*dy]]),\n",
    "                 np.array([[center[0]-dx, center[1]-dy], [center[0]-dx, center[1]+dy]])]\n",
    "    return points\n",
    "\n",
    "def get_manycells_boundary(centers, topology='rectangular'):\n",
    "    points=[]\n",
    "    for center in centers:\n",
    "        points+=get_cell_boundary(center, topology)\n",
    "    points_unique, counts = np.unique(np.round(np.array(points),4), axis=0, return_counts=True)\n",
    "    return points_unique[counts==1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14478ab0",
   "metadata": {},
   "source": [
    "Now we calculate and plot the SOM grid color-coded by the average true redshift of the target sample (left panel) and the reference sample (right panel) to show the reference sample is indeed representing the redshift of the target galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_photZ_ref = np.zeros_like(SOM.umatrix).reshape(-1)  # mean photometric redshift of reference data in each cell/cluster\n",
    "mean_specZ_ref = np.zeros_like(SOM.umatrix).reshape(-1)  # mean spectroscopic redshift of reference data in each cell/cluster\n",
    "\n",
    "mean_photZ_target = np.zeros_like(SOM.umatrix).reshape(-1)   # mean photometric redshift of target data in each cell/cluster\n",
    "mean_specZ_target = np.zeros_like(SOM.umatrix).reshape(-1)   # mean spectroscopic redshift of target data in each cell/cluster\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    \n",
    "    mean_photZ_ref[som_cluster_inds==i] = np.median(bpz_spec[ref_som_clusterind==i])\n",
    "    mean_specZ_ref[som_cluster_inds==i] = np.median(ref_data.data['photometry']['redshift'][ref_som_clusterind==i])\n",
    "    \n",
    "    mean_photZ_target[som_cluster_inds==i] = np.median(bpz_phot[target_som_clusterind==i])\n",
    "    mean_specZ_target[som_cluster_inds==i] = np.median(target_data.data['photometry']['redshift'][target_som_clusterind==i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b22395",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
    "plot_som(ax[0], mean_specZ_target.reshape(dim, dim), grid_type=grid_type, colormap=cm.coolwarm, cbar_name='mean true redshift of the target sample', vmin=bin_low, vmax=bin_high)\n",
    "ax[0].set_title('Target sample')\n",
    "\n",
    "plot_som(ax[1], mean_specZ_ref.reshape(dim, dim), grid_type=grid_type, colormap=cm.coolwarm, cbar_name='mean true redshift of the reference sample', vmin=bin_low, vmax=bin_high)\n",
    "\n",
    "ax[1].set_title('Reference sample')\n",
    "plot_cluster_boundaries(ax[0], SOM, n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1392a4e6",
   "metadata": {},
   "source": [
    "# Now let's do the quality control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71510a",
   "metadata": {},
   "source": [
    "Quality control means selecting a subset of the clusters/SOM cells where the target galaxies are well represented by the reference sample.\n",
    "We evaluate the \"goodness-of-reference\" by the two criteria given by https://arxiv.org/pdf/2007.15635 \n",
    "\n",
    "Quality cut 1 (QC1):\n",
    "\n",
    "$\\frac{\\left|\\left\\langle z_{\\text {spec }}\\right\\rangle-\\left\\langle Z_{\\mathrm{B}}\\right\\rangle\\right|}{\\operatorname{nMAD}\\left(\\left\\langle z_{\\text {spec }}\\right\\rangle-\\left\\langle Z_{\\mathrm{B}}\\right\\rangle\\right)}>5$\n",
    "\n",
    "This QC will remove outliers in the distribution of photo-$z$.\n",
    "\n",
    "Quality cut 2 (QC2):\n",
    "\n",
    "$\\left|\\left\\langle Z_B\\right\\rangle_{\\text {spec }}-\\left\\langle Z_B\\right\\rangle_{\\text {phot }}\\right|>0.02$\n",
    "\n",
    "This QC will remove clusters in which the target and reference sample have very different photo-$z$, which means the reference galaxies are not representative.\n",
    "\n",
    "We also try to combine these two QCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c9bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "zmean_diff_cluster_qc1 = np.zeros(n_clusters)\n",
    "zmean_diff_cluster_qccombined = np.zeros(n_clusters)\n",
    "\n",
    "for i in range(n_clusters):   \n",
    "    \n",
    "    zmean_diff_cluster_qc1[i] = np.fabs(np.median(ref_data.data['photometry']['redshift'][ref_som_clusterind==i]) - np.median(bpz_phot[target_som_clusterind==i]))\n",
    "        \n",
    "    zmean_diff_cluster_qccombined[i] = np.fabs(np.median(bpz_phot[target_som_clusterind==i])-np.median(bpz_spec[ref_som_clusterind==i]))\n",
    "    \n",
    "\n",
    "cluster_ind_good = np.where(~np.isnan(zmean_diff_cluster_qccombined))\n",
    "cluster_ind_good_qc1 = np.where(zmean_diff_cluster_qc1<max(median_abs_deviation((mean_specZ_ref-mean_photZ_ref)[~np.isnan(mean_specZ_ref-mean_photZ_ref)])*5, 0))\n",
    "cluster_ind_good_qc2 = np.where(zmean_diff_cluster_qccombined<0.02)\n",
    "\n",
    "cluster_ind_good_qccombined = np.intersect1d(cluster_ind_good_qc2, cluster_ind_good_qc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0812f5",
   "metadata": {},
   "source": [
    "Here is the cluster occupation distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfd604",
   "metadata": {},
   "source": [
    "And here is the mean redshift per cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f850fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
    "\n",
    "plot_som(ax[0], np.fabs(mean_specZ_ref-mean_photZ_target).reshape(dim,dim)/max(median_abs_deviation((mean_specZ_ref-mean_photZ_ref)[~np.isnan(mean_specZ_ref-mean_photZ_ref)])*5, 0), grid_type=grid_type, colormap=cm.coolwarm, cbar_name=r'$\\frac{\\left|\\left\\langle z_{\\text {spec }}\\right\\rangle-\\left\\langle Z_{\\mathrm{B}}\\right\\rangle\\right|}{\\operatorname{nMAD}\\left(\\left\\langle z_{\\text {spec }}\\right\\rangle-\\left\\langle Z_{\\mathrm{B}}\\right\\rangle\\right)\\times 5}$', vmin=0, vmax=1)\n",
    "\n",
    "plot_cluster_boundaries(ax[0], SOM, n_clusters, cluster_inds=cluster_ind_good_qc1[0])\n",
    "\n",
    "zmean_diff = np.fabs(mean_specZ_target - mean_specZ_ref).reshape(dim, dim)\n",
    "\n",
    "plot_som(ax[1], (zmean_diff)/0.02, grid_type=grid_type, colormap=cm.coolwarm, cbar_name=r'$\\left|\\left\\langle Z_B\\right\\rangle_{\\text {spec }}-\\left\\langle Z_B\\right\\rangle_{\\text {phot }}\\right|/0.02$', vmin=0, vmax=1)\n",
    "\n",
    "plot_cluster_boundaries(ax[1], SOM, n_clusters, cluster_inds=cluster_ind_good_qc2[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d5a6e",
   "metadata": {},
   "source": [
    "Now that we have illustrated what exactly we have constructed, let's use the SOM to predict the redshift distribution for a set of photometric objects.  \n",
    "We first summarize the case withouth QC, then the three QCs (QC1, QC2, QC1+QC2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6498f5e",
   "metadata": {},
   "source": [
    "Note that we have removed the 'photometry' group, we will specify the `phot_groupname` as \"\" in the parameters below.<br>\n",
    "As before, let us specify our initialization params for the SOMocluSummarizer stage, including:<br>\n",
    "`model`: name of the pickled model that we created, in this case \"output_SOM_model.pkl\"<br>\n",
    "`hdf5_groupname` (str): hdf5 group for our photometric data (in our case \"\")<br>\n",
    "`objid_name` (str): string specifying the name of the ID column, if present photom data, will be written out to cellid_output file<br>\n",
    "`spec_groupname` (str): hdf5 group for the spectroscopic data<br>\n",
    "`nzbins` (int): number of bins to use in our histogram ensemble<br>\n",
    "`n_clusters` (int): number of hierarchical clusters<br>\n",
    "`nsamples` (int): number of bootstrap samples to generate<br>\n",
    "`output` (str): name of the output qp file with N samples<br>\n",
    "`single_NZ` (str): name of the qp file with fiducial distribution<br>\n",
    "`uncovered_cell_file` (str): name of hdf5 file containing a list of all of the cells with phot data but no spec-z objects: photometric objects in these cells will *not* be accounted for in the final N(z), and should really be removed from the sample before running the summarizer.  Note that we return a single integer that is constructed from the pairs of SOM cell indices via `np.ravel_multi_index`(indices).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9974d04",
   "metadata": {},
   "source": [
    "Now let's initialize and run the summarizer.  One feature of the SOM: if any SOM cells contain photometric data but do not contain any redshifts values in the spectroscopic set, then no reasonable redshift estimate for those objects is defined, and they are skipped.  The method currently prints the indices of uncovered cells, we may modify the algorithm to actually output the uncovered galaxies in a separate file in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d092c",
   "metadata": {},
   "source": [
    "Let's open the fiducial N(z) file, plot it, and see how it looks, and compare it to the true tomographic bin file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_ens = qp.read('SOM_ensemble.hdf5')\n",
    "\n",
    "target_nz_hist, zbin = get_cont_hist(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good)], np.linspace(0,3,101))\n",
    "\n",
    "fid_ens = qp.read('fiducial_SOMoclu_NZ.hdf5')\n",
    "som_nz_hist = np.squeeze(fid_ens.pdf(zbin))\n",
    "\n",
    "full_ens = qp.read(\"SOM_ensemble.hdf5\")\n",
    "full_means = full_ens.mean().flatten()\n",
    "full_stds = full_ens.std().flatten()\n",
    "true_full_mean = np.mean(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good)])\n",
    "true_full_std = np.std(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good)])\n",
    "# mean and width of bootstraps\n",
    "full_mu = np.mean(full_means)\n",
    "full_sig = np.std(full_means)\n",
    "full_norm = norm(loc=full_mu, scale=full_sig)\n",
    "grid = np.linspace(0, .7, 301)\n",
    "full_uncert = full_norm.pdf(grid)*2.51*full_sig\n",
    "\n",
    "print('===========This is the fiducial case==================')\n",
    "\n",
    "print(\"The mean redshift of the SOM ensemble is: \"+str(round(np.mean(full_means),4)) + '+-' + str(round(np.std(full_means),4)))\n",
    "print(\"The mean redshift of the real data is: \"+str(round(true_full_mean,4)))\n",
    "print(\"The bias of mean redshift is:\"+str(round(np.mean(full_means)-true_full_mean,4)) + '+-' + str(round(np.std(full_means),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_model_qc1=DS.read_file('som_model_qc1',  ModelHandle, \"output_SOMoclu_model.pkl\",)\n",
    "\n",
    "summ_dict_qc1 = dict(model=som_model_qc1, hdf5_groupname='photometry',\n",
    "                 spec_groupname='photometry', nzbins=101, nsamples=25,\n",
    "                 output='SOM_ensemble_qc1.hdf5', single_NZ='fiducial_SOMoclu_NZ_qc1.hdf5',\n",
    "                 n_clusters=n_clusters,\n",
    "                 uncovered_cell_file='all_uncovered_cells_qc1.hdf5',\n",
    "                 objid_name='id',\n",
    "                 cellid_output='output_cellIDs_qc1.hdf5', useful_clusters=cluster_ind_good_qc1[0])\n",
    "\n",
    "som_summarizer_qc1 = SOMocluSummarizer.make_stage(name='SOMoclu_summarizer_qc1', **summ_dict_qc1)\n",
    "som_summarizer_qc1.summarize(target_data, ref_data)\n",
    "\n",
    "fid_ens_qc1 = qp.read(\"fiducial_SOMoclu_NZ_qc1.hdf5\")\n",
    "boot_ens_qc1 = qp.read('SOM_ensemble_qc1.hdf5')\n",
    "target_nz_hist_qc1, zbin_qc1 = get_cont_hist(target_data.data['photometry']['redshift'], np.linspace(0,3,101))\n",
    "som_nz_hist_qc1 = np.squeeze(fid_ens_qc1.pdf(zbin))\n",
    "\n",
    "target_nz_hist_qc1_true, zbin = get_cont_hist(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good_qc1)], np.linspace(0,3,101))\n",
    "\n",
    "full_ens_qc1 = qp.read(\"SOM_ensemble_qc1.hdf5\")\n",
    "full_means_qc1 = full_ens_qc1.mean().flatten()\n",
    "full_stds_qc1 = full_ens_qc1.std().flatten()\n",
    "true_full_mean_qc1 = np.mean(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good_qc1)])\n",
    "true_full_std_qc1 = np.std(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good_qc1)])\n",
    "# mean and width of bootstraps\n",
    "full_mu_qc1 = np.mean(full_means_qc1)\n",
    "full_sig_qc1 = np.std(full_means_qc1)\n",
    "full_norm_qc1 = norm(loc=full_mu_qc1, scale=full_sig_qc1)\n",
    "grid = np.linspace(0, .7, 301)\n",
    "full_uncert_qc1 = full_norm_qc1.pdf(grid)*2.51*full_sig_qc1\n",
    "\n",
    "print('\\n\\n===========This is the QC1 case==================')\n",
    "\n",
    "print(\"The mean redshift of the SOM ensemble is: \"+str(round(np.mean(full_means_qc1),4)) + '+-' + str(round(np.std(full_means_qc1),4)))\n",
    "print(\"The mean redshift of the real data is: \"+str(round(true_full_mean_qc1,4)))\n",
    "print(\"The bias of mean redshift is:\"+str(round(np.mean(full_means_qc1)-true_full_mean_qc1,4)) + '+-' + str(round(np.std(full_means_qc1),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26885c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "som_model_qc2=DS.read_file('som_model_qc2',  ModelHandle, \"output_SOMoclu_model.pkl\",)\n",
    "\n",
    "summ_dict_qc2 = dict(model=som_model_qc2, hdf5_groupname='photometry',\n",
    "                 spec_groupname='photometry', nzbins=101, nsamples=25,\n",
    "                 output='SOM_ensemble_qc2.hdf5', single_NZ='fiducial_SOMoclu_NZ_qc2.hdf5',\n",
    "                 n_clusters=n_clusters,\n",
    "                 uncovered_cell_file='all_uncovered_cells_qc2.hdf5',\n",
    "                 objid_name='id',\n",
    "                 cellid_output='output_cellIDs_qc2.hdf5', useful_clusters=cluster_ind_good_qc2[0])\n",
    "\n",
    "som_summarizer_qc2 = SOMocluSummarizer.make_stage(name='SOMoclu_summarizer_qc2', **summ_dict_qc2)\n",
    "som_summarizer_qc2.summarize(target_data, ref_data)\n",
    "\n",
    "fid_ens_qc2 = qp.read(\"fiducial_SOMoclu_NZ_qc2.hdf5\")\n",
    "boot_ens_qc2 = qp.read('SOM_ensemble_qc2.hdf5')\n",
    "target_nz_hist_qc2, zbin_qc2 = get_cont_hist(target_data.data['photometry']['redshift'], np.linspace(0,3,101))\n",
    "som_nz_hist_qc2 = np.squeeze(fid_ens_qc2.pdf(zbin))\n",
    "target_nz_hist_qc2_true, zbin = get_cont_hist(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good_qc2)], np.linspace(0,3,101))\n",
    "\n",
    "full_ens_qc2 = qp.read(\"SOM_ensemble_qc2.hdf5\")\n",
    "full_means_qc2 = full_ens_qc2.mean().flatten()\n",
    "full_stds_qc2 = full_ens_qc2.std().flatten()\n",
    "true_full_mean_qc2 = np.mean(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good_qc2)])\n",
    "true_full_std_qc2 = np.std(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good_qc2)])\n",
    "# mean and width of bootstraps\n",
    "full_mu_qc2 = np.mean(full_means_qc2)\n",
    "full_sig_qc2 = np.std(full_means_qc2)\n",
    "full_norm_qc2 = norm(loc=full_mu_qc2, scale=full_sig_qc2)\n",
    "grid = np.linspace(0, .7, 301)\n",
    "full_uncert_qc2 = full_norm_qc2.pdf(grid)*2.51*full_sig_qc2\n",
    "\n",
    "print(\"\\n\\n===========This is the QC2 case==================\")\n",
    "\n",
    "print(\"The mean redshift of the SOM ensemble is: \"+str(round(np.mean(full_means_qc2),4)) + '+-' + str(round(np.std(full_means_qc2),4)))\n",
    "print(\"The mean redshift of the real data is: \"+str(round(true_full_mean_qc2,4)))\n",
    "print(\"The bias of mean redshift is:\"+str(round(np.mean(full_means_qc2)-true_full_mean_qc2,4)) + '+-' + str(round(np.std(full_means_qc2),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_model_qccombined=DS.read_file('som_model_qccombined',  ModelHandle, \"output_SOMoclu_model.pkl\",)\n",
    "\n",
    "summ_dict_qccombined = dict(model=som_model_qccombined, hdf5_groupname='photometry',\n",
    "                 spec_groupname='photometry', nzbins=101, nsamples=25,\n",
    "                 output='SOM_ensemble_qccombined.hdf5', single_NZ='fiducial_SOMoclu_NZ_qccombined.hdf5',\n",
    "                 n_clusters=n_clusters,\n",
    "                 uncovered_cell_file='all_uncovered_cells_qccombined.hdf5',\n",
    "                 objid_name='id',\n",
    "                 cellid_output='output_cellIDs_qccombined.hdf5', useful_clusters=cluster_ind_good_qccombined)\n",
    "\n",
    "som_summarizer_qccombined = SOMocluSummarizer.make_stage(name='SOMoclu_summarizer_qccombined', **summ_dict_qccombined)\n",
    "som_summarizer_qccombined.summarize(target_data, ref_data)\n",
    "\n",
    "fid_ens_qccombined = qp.read(\"fiducial_SOMoclu_NZ_qccombined.hdf5\")\n",
    "boot_ens_qccombined = qp.read('SOM_ensemble_qccombined.hdf5')\n",
    "target_nz_hist_qccombined, zbin_qccombined = get_cont_hist(target_data.data['photometry']['redshift'], np.linspace(0,3,101))\n",
    "som_nz_hist_qccombined = np.squeeze(fid_ens_qccombined.pdf(zbin))\n",
    "target_nz_hist_qccombined_true, zbin = get_cont_hist(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good_qccombined)], np.linspace(0,3,101))\n",
    "\n",
    "full_ens_qccombined = qp.read(\"SOM_ensemble_qccombined.hdf5\")\n",
    "full_means_qccombined = full_ens_qccombined.mean().flatten()\n",
    "full_stds_qccombined = full_ens_qccombined.std().flatten()\n",
    "true_full_mean_qccombined = np.mean(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good_qccombined)])\n",
    "true_full_std_qccombined = np.std(target_data.data['photometry']['redshift'][np.in1d(target_som_clusterind, cluster_ind_good_qccombined)])\n",
    "# mean and width of bootstraps\n",
    "full_mu_qccombined = np.mean(full_means_qccombined)\n",
    "full_sig_qccombined = np.std(full_means_qccombined)\n",
    "full_norm_qccombined = norm(loc=full_mu_qccombined, scale=full_sig_qccombined)\n",
    "grid = np.linspace(0, .7, 301)\n",
    "full_uncert_qccombined = full_norm_qccombined.pdf(grid)*2.51*full_sig_qccombined\n",
    "\n",
    "print(\"\\n\\n===========This is the QC1+QC2 case==================\")\n",
    "\n",
    "print(\"The mean redshift of the SOM ensemble is: \"+str(round(np.mean(full_means_qccombined),4)) + '+-' + str(round(np.std(full_means_qccombined),4)))\n",
    "print(\"The mean redshift of the real data is: \"+str(round(true_full_mean_qccombined,4)))\n",
    "print(\"The bias of mean redshift is:\"+str(round(np.mean(full_means_qccombined)-true_full_mean_qccombined,4)) + '+-' + str(round(np.std(full_means_qccombined),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c36b9d4",
   "metadata": {},
   "source": [
    "Now we plot the true/calibrated redshift distributions of the four cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50418dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(24,12))\n",
    "ax = ax.flatten()\n",
    "ax[0].set_xlabel(\"redshift\", fontsize=15)\n",
    "ax[0].set_ylabel(\"N(z)\", fontsize=15)\n",
    "ax[0].plot(zbin, target_nz_hist, label='True N(z)')\n",
    "ax[0].plot(zbin, som_nz_hist,  color='C1',label='SOM N(z)')\n",
    "\n",
    "for i in range(boot_ens.npdf):\n",
    "    #ax = plt.subplot(2,3,i+1)\n",
    "    pdf = np.squeeze(boot_ens[i].pdf(zbin))\n",
    "    if i == 0:        \n",
    "        ax[0].plot(zbin, pdf, color='C1',zorder=0, alpha=0.2)\n",
    "    else:\n",
    "        ax[0].plot(zbin, pdf, color='C1',zorder=0, alpha=0.2)\n",
    "\n",
    "ax[1].set_title(f'{round(som_summarizer_qc1.neff_p_to_neff / som_summarizer.neff_p_to_neff*100, 2)}% galaxies kept')\n",
    "ax[1].plot(zbin_qc1, target_nz_hist_qc1_true, color='C0',label='True N(z), QC1 selected')\n",
    "ax[1].plot(zbin_qc1, som_nz_hist_qc1, color='C1',label='SOM N(z), QC1 selected')\n",
    "ax[1].set_xlabel(\"redshift\", fontsize=15)\n",
    "ax[1].set_ylabel(\"N(z)\", fontsize=15)\n",
    "for i in range(boot_ens.npdf):\n",
    "    #ax = plt.subplot(2,3,i+1)\n",
    "    pdf = np.squeeze(boot_ens_qc1[i].pdf(zbin))\n",
    "    if i == 0:        \n",
    "        ax[1].plot(zbin, pdf, color='C1',zorder=0, alpha=0.2)\n",
    "    else:\n",
    "        ax[1].plot(zbin, pdf, color='C1',zorder=0, alpha=0.2)\n",
    "\n",
    "ax[2].set_title(f'{round(som_summarizer_qc2.neff_p_to_neff / som_summarizer.neff_p_to_neff*100, 2)}% galaxies kept')\n",
    "ax[2].plot(zbin_qc2, target_nz_hist_qc2_true, color='C0',label='True N(z), QC2 selected')\n",
    "ax[2].plot(zbin_qc2, som_nz_hist_qc2, color='C1',label='SOM N(z), QC2 selected')\n",
    "ax[2].set_xlabel(\"redshift\", fontsize=15)\n",
    "ax[2].set_ylabel(\"N(z)\", fontsize=15)\n",
    "for i in range(boot_ens.npdf):\n",
    "    #ax = plt.subplot(2,3,i+1)\n",
    "    pdf = np.squeeze(boot_ens_qc2[i].pdf(zbin))\n",
    "    if i == 0:        \n",
    "        ax[2].plot(zbin, pdf, color='C1',zorder=0, alpha=0.2)\n",
    "    else:\n",
    "        ax[2].plot(zbin, pdf, color='C1',zorder=0, alpha=0.2)\n",
    "\n",
    "ax[3].set_title(f'{round(som_summarizer_qccombined.neff_p_to_neff / som_summarizer.neff_p_to_neff*100, 2)}% galaxies kept')\n",
    "ax[3].plot(zbin_qccombined, target_nz_hist_qccombined_true, color='C0',label='True N(z), QC1+2 selected')\n",
    "ax[3].plot(zbin_qccombined, som_nz_hist_qccombined, color='C1',label='SOM N(z), QC1+2 selected')\n",
    "ax[3].set_xlabel(\"redshift\", fontsize=15)\n",
    "ax[3].set_ylabel(\"N(z)\", fontsize=15)\n",
    "for i in range(boot_ens.npdf):\n",
    "    #ax = plt.subplot(2,3,i+1)\n",
    "    pdf = np.squeeze(boot_ens_qccombined[i].pdf(zbin))\n",
    "    if i == 0:        \n",
    "        ax[3].plot(zbin, pdf, color='C1',zorder=0, alpha=0.2)\n",
    "    else:\n",
    "        ax[3].plot(zbin, pdf, color='C1',zorder=0, alpha=0.2)\n",
    "\n",
    "ax[0].legend(fontsize=15)\n",
    "ax[1].legend(fontsize=15)\n",
    "ax[2].legend(fontsize=15)\n",
    "ax[3].legend(fontsize=15)\n",
    "ax[0].set_xlim(0,1.5)\n",
    "ax[1].set_xlim(0,1.5)\n",
    "ax[2].set_xlim(0,1.5)\n",
    "ax[3].set_xlim(0,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe48f5",
   "metadata": {},
   "source": [
    "The following box plot summarizes the bias in the redshift estimation for the four cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3041e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [full_means_qccombined-true_full_mean_qccombined, full_means_qc2-true_full_mean_qc2, full_means_qc1-true_full_mean_qc1, full_means-true_full_mean]\n",
    "\n",
    "#plt.boxplot(data)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.boxplot(data, vert = 0)\n",
    "ax.axvline(0,1,0, color='C0')\n",
    "ax.set_xlim(-0.02,0.02)\n",
    "ax.set_xlabel(r'$\\Delta\\left\\langle z \\right\\rangle$')\n",
    "ax.set_yticklabels(['SOM N(z), QC1+QC2', 'SOM N(z), QC2','SOM N(z), QC1', 'SOM N(z)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77089663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/net/home/fohlen14/yanza21/research/src/RAIL_branches/RAIL/src/rail/estimation')\n",
    "\n",
    "#from algos.somocluSOM import SOMocluSummarizer\n",
    "\n",
    "n_clusterss = np.linspace(50, 1500, 10, dtype=int)\n",
    "\n",
    "true_full_mean = np.mean(target_data.data['photometry']['redshift'])\n",
    "true_full_std = np.std(target_data.data['photometry']['redshift'])\n",
    "mu_diff = np.zeros(n_clusterss.size)\n",
    "means_diff = np.zeros((n_clusterss.size, 50))\n",
    "\n",
    "std_diff_mean = np.zeros(n_clusterss.size)\n",
    "neff_p_to_neff = np.zeros(n_clusterss.size)\n",
    "#neff_p_to_neff = np.zeros((n_clusterss.size, 25))\n",
    "std_diff = np.zeros((n_clusterss.size, 50))\n",
    "for i, n_clusters_ in enumerate(n_clusterss):\n",
    "    summ_dict = dict(model=\"output_SOMoclu_model.pkl\", hdf5_groupname='photometry',\n",
    "                 spec_groupname='photometry', nzbins=101, nsamples=50,\n",
    "                 output='SOM_ensemble.hdf5', single_NZ='fiducial_SOMoclu_NZ.hdf5',\n",
    "                 n_clusters=n_clusters_,\n",
    "                 uncovered_cluster_file ='all_uncovered_cells.hdf5',\n",
    "                 objid_name='id',\n",
    "                 cellid_output='output_cellIDs.hdf5')\n",
    "    som_summarizer = SOMocluSummarizer.make_stage(name='SOMoclu_summarizer', aliases=dict(model=\"model_somoclu\"), **summ_dict)    \n",
    "    som_summarizer.summarize(target_data, ref_data)\n",
    "    \n",
    "    full_ens = qp.read(\"SOM_ensemble.hdf5\")\n",
    "    full_means = full_ens.mean().flatten()\n",
    "    full_stds = full_ens.std().flatten()\n",
    "    \n",
    "    # mean and width of bootstraps\n",
    "    mu_diff[i] = np.mean(full_means) - true_full_mean\n",
    "    means_diff[i] = full_means - true_full_mean\n",
    "    \n",
    "    std_diff_mean[i] = np.mean(full_stds) - true_full_std\n",
    "    std_diff[i] = full_stds - true_full_std\n",
    "    neff_p_to_neff[i] = som_summarizer.neff_p_to_neff\n",
    "    #neff_p_to_neff_mean[i] = np.mean(som_summarizer.neff_p_to_neff)\n",
    "    full_sig = np.std(full_means)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(20,5))\n",
    "\n",
    "'''for i in range(25):\n",
    "    axes[0].plot(n_clusterss, means_diff.T[i], lw=0.2, color='C1')'''\n",
    "axes[0].plot(n_clusterss, mu_diff, lw=1, color='k')\n",
    "axes[0].axhline(0,1,0)\n",
    "axes[0].set_xlabel('Number of clusters')\n",
    "axes[0].set_ylabel(r'$\\left\\langle z \\right\\rangle - \\left\\langle z \\right\\rangle_{\\mathrm{true}}$')\n",
    "\n",
    "'''for i in range(25):\n",
    "    axes[1].plot(n_clusterss, std_diff.T[i], lw=0.2, color='C1')'''\n",
    "axes[1].plot(n_clusterss, std_diff_mean, lw=1, color='k')\n",
    "axes[1].axhline(0,1,0)\n",
    "\n",
    "axes[1].set_xlabel('Number of clusters')\n",
    "axes[1].set_ylabel(r'$\\mathrm{std}(z) - \\mathrm{std}(z)_{\\mathrm{true}}$')\n",
    "\n",
    "\n",
    "'''for i in range(25):\n",
    "    axes[2].plot(n_clusterss, neff_p_to_neff.T[i]*100, lw=0.2, color='C1')'''\n",
    "axes[2].plot(n_clusterss, neff_p_to_neff*100, lw=1, color='k')\n",
    "\n",
    "axes[2].set_xlabel('Number of clusters')\n",
    "axes[2].set_ylabel(r'$n_{\\mathrm{eff}}\\'/n_{\\mathrm{eff}}$(%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d37daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
