{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac442d9",
   "metadata": {},
   "source": [
    "# BPZ Lite Demo\n",
    "\n",
    "**Authors:** Sam Schmidt\n",
    "\n",
    "**Last Successfully Run:** Nov 14, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85906442-6d29-407a-8d80-4108d45af015",
   "metadata": {},
   "source": [
    "This notebook will go through a simple example of running rail_bpz estimate and inform stages with a small set of test data that ships with the RAIL package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b30a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import qp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import desc_bpz\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utils import RAILDIR\n",
    "from rail.estimation.algos.bpz_lite import BPZliteInformer, BPZliteEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c8503-74ee-4de7-b0f7-a2d8d1398db7",
   "metadata": {},
   "source": [
    "First, let's set up a DataStore, for more info on the DataStore, see the RAIL example notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190c489-b80c-4f4c-9eb0-19b3efe42cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab08dcf-72d2-4a6f-8037-14301f922c17",
   "metadata": {},
   "source": [
    "First, let's grab the training and test data files that we will use in this example, they are included with RAIL, so we can access their location via the RAILDIR path.  Both file contain data drawn from the cosmoDC2_v1.1.4 truth extragalactic catalog generated by DESC with model 10-year-depth magnitude uncertainties.  The training data contains roughly 10,000 galaxies, while the test data contains roughly 20,000.  Both sets are representative down to a limiting apparent magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e74f88-a0d4-42af-a4ac-4deefd0c8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFile = os.path.join(RAILDIR, 'rail/examples_data/testdata/test_dc2_training_9816.hdf5')\n",
    "testFile = os.path.join(RAILDIR, 'rail/examples_data/testdata/test_dc2_validation_9816.hdf5')\n",
    "training_data = DS.read_file(\"training_data\", TableHandle, trainFile)\n",
    "test_data = DS.read_file(\"test_data\", TableHandle, testFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaac331-aa5a-4a90-8b85-16929cffc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAILDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d5363-af4e-4478-9820-29214292bf16",
   "metadata": {},
   "source": [
    "## running BPZliteEstimator with a pre-existing model\n",
    "\n",
    "BPZ is a template-fitting code that works by calculating the chi^2 value for observed photometry and errors compared with a grid of theoretical photometric fluxes generated from a set of template SEDs at each of a grid of redshift values.  These chi^2 values are converted to likelihoods.  If desired, a Bayesian prior can be applied that parameterizes the expected distribution of galaxies in terms of both probability of a \"broad\" SED type as a function of apparent magnitude, and the probability of a galaxy being at a certain redshift given broad SED type and apparent magnitude.  The product of this prior and the likelihoods is then summed over the SED types to return a marginalized posterior PDF, or p(z) for each galaxy.  If the config option `no_prior` is set to `True`, then no prior is applied, and BPZliteEstimator will return a likelihood for each galaxy rather than a posterior.\n",
    "\n",
    "\n",
    "`bpz-1.99.3`, the code written by Dan Coe and Narcisso Benitez and available at https://www.stsci.edu/~dcoe/BPZ/, uses a default set of eight SED templates: four templates from Coleman, Wu, & Weedman (CWW, one Elliptical, two Spirals Sbc and Scd, and one Irregular), two starburst (WB) templates, and two very blue star forming templates generated using Bruzual & Charlot models with very young ages of 25Myr and 5Myr.  The original BPZ paper, Benitez(2000) computed a \"default\" prior fit to data from the Hubble Deep Field North (HDFN).  A pickle file with these parameters and the default SEDs are included with RAIL, named `CWW_HDFN_prior.pkl`.  You can run BPZliteEstimator with these default templates and priors without doing any training, the equivalent of \"running BPZ with the defaults\" had you downloaded bpz-1.99.3 and run it.  **Note, however**, that the cosmoDC2_v1.1.4 dataset has a population of galaxy SEDs that are fairly different from the \"default\" CWWSB templates, and the prior distributions do not exactly match.  So, you will get results that do not look particularly good.  We will demonstrate that use case here, though, as it is the most simple way to run the code out of the box (and illustrates the dangers of grabbing code and running it out of the box):\n",
    "\n",
    "We need to set up a RAIL stage for the default run of BPZ, including specifying the location of the model pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c3e9f-7080-4334-bcf1-7993239b69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfnfile = os.path.join(RAILDIR, \"rail/examples_data/estimation_data/data/CWW_HDFN_prior.pkl\")\n",
    "default_dict = dict(hdf5_groupname=\"photometry\", output=\"bpz_results_defaultprior.hdf5\",\n",
    "                    prior_band=\"mag_i_lsst\", no_prior=False)\n",
    "run_default = BPZliteEstimator.make_stage(name=\"bpz_def_prior\", model=hdfnfile, **default_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bba83c-d3ed-4385-852c-639e59170c48",
   "metadata": {},
   "source": [
    "Let's run the estimate stage, if this is the first run of ``BPZliteEstimator`` or ``BPZliteInformer``, you may see a bunch of output lines as ``DESC_BPZ`` creates the synthetic photometry \"AB\" files for the SEDs and filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cd587-122e-41ef-9d3f-77333a54c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_default.estimate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfd0ce-7765-4bfd-b3a0-2b3beb0cccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_result = qp.read(\"bpz_results_defaultprior.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd084c-4fab-459d-b39c-6f82240f1733",
   "metadata": {},
   "source": [
    "Plot the mode of these \"default run\" PDFs against the true redshifts, we have the true redshifts stored in the `test_data` in the DataStore, and the modes are stored as ancillary data in the results that we just produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb0083-750b-496a-b8c0-871c98ea327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = test_data()['photometry']['redshift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b887438-f9d9-491d-8ca0-cf313fab1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(sz, default_result.ancil['zmode'].flatten(), s=2, c='k', label='default prior mode')\n",
    "plt.plot([0,3], [0,3], 'b--')\n",
    "plt.xlabel(\"redshift\")\n",
    "plt.ylabel(\"photo-z mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487194d-1af0-4a1f-ac35-06490ab7a735",
   "metadata": {},
   "source": [
    "Results do not look bad, there are some catastrophic outliers, and there appears to be some bias in the redshift estimates, but as the SED templates have slightly systematically different colors than our test data, that is just what we expect to see.\n",
    "\n",
    "BPZliteEstimator also produces a `tb` , a \"best-fit type\"; that is, the SED template with the highest posterior probability contribution at the value of the `zmode`. We can plot up a color color diagram of our test data and we should see a pattern in color space reflecting the different populations in different areas of color space.  `tb` is stored as an 1-indexed integer corresponding the the number of the SED in our template set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef1cc3-2368-4426-b570-0a788f39846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colordict = {}\n",
    "bands = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "for i in range(5):\n",
    "    colordict[f'{bands[i]}{bands[i+1]}'] = test_data()['photometry'][f'mag_{bands[i]}_lsst'] - test_data()['photometry'][f'mag_{bands[i+1]}_lsst']\n",
    "colordict['tb'] = default_result.ancil['tb'].flatten()\n",
    "colordict['todds'] = default_result.ancil['todds'].flatten()\n",
    "colordict['sz'] = sz\n",
    "colordf = pd.DataFrame(colordict)\n",
    "sed_col = ['r', 'g', 'm', 'b', 'royalblue', 'gray', 'k']\n",
    "sed_label = ['Ell', 'Sbc', 'Scd', 'Im', 'SB3', 'SB2', 'ssp25Myr', 'ssp5Myr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0a32a-382f-42dc-afda-527f6e6500dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i,col, lab in zip(range(8), sed_col, sed_label):\n",
    "    tbmask = (np.isclose(colordf['tb'], i+1)) # note the 1-offset here because of how DESC_BPZ labels the SED types\n",
    "    plt.scatter(colordf['gr'][tbmask], colordf['ri'][tbmask], color=col, s=2, label=lab)\n",
    "plt.xlim(-1,2.25)\n",
    "plt.xlabel(\"g-r\", fontsize=13)\n",
    "plt.ylabel(\"r-i\", fontsize=13)\n",
    "plt.legend(loc='upper left', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b9600-109a-48df-a050-bc1b2ac31406",
   "metadata": {},
   "source": [
    "As expected, we see Ellptical galaxies with redder colors, and the bluest galaxies being star-forming galaxies with power-law-like SED shapes, with the other types spaced out in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee27ab8-2282-45ae-99bc-a8fcc5691ee1",
   "metadata": {},
   "source": [
    "BPZliteEstimator also computes a quantity called `todds`, which is the fraction of posterior probability in the best-fit SED relative to the overall probability of all templates.  If the value is high, then a single SED is providing more of the probability.  If the value is low, then multiple SEDs are contributing, which means that `tb`, the best-fit-SED-type, is less meaningful.  The values of todds whould be lower where SEDs have degenerate broad-band colors, let's highlight the values of low todds and see where they lie in color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32143555-6e79-4dd5-a128-40afdb8c4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "lowtoddsmask = (colordf['todds']<0.25)\n",
    "plt.scatter(colordf['gr'], colordf['ri'], color='k', s=8)\n",
    "plt.scatter(colordf['gr'][lowtoddsmask], colordf['ri'][lowtoddsmask], color='r', s=4, label='todds < 0.25')\n",
    "plt.xlim(-1,2.25)\n",
    "plt.xlabel(\"g-r\", fontsize=13)\n",
    "plt.ylabel(\"r-i\", fontsize=13)\n",
    "plt.legend(loc='upper left', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0fdd7-6b32-4327-815e-80059ab4c4de",
   "metadata": {},
   "source": [
    "If you compare the areas of color space with low todds you can see that it corresponds to portions of color space where multiple best-fit SED types lie very close in color, e.g. areas where Sbc, Scd, and Im galaxies all have similar g-r and r-i colors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d59ce-ca73-4bf3-9f3d-682c4dbdcb3e",
   "metadata": {},
   "source": [
    "## BPZliteInformer: training a custom prior\n",
    "\n",
    "If you want to go beyond the default prior, there is an `BPZliteInformer` stage that allows you to use a training dataset to fit a custom parameterized prior that better matches the magnitude and type distributions of the training set.\n",
    "\n",
    "`bpz-1.99.3` and our local fork, `DESC_BPZ` both parameterize the Bayesian prior using the form described in Benitez (2000), where the individual SED types are grouped into \"broad types\", e.g. 1 Elliptical makes up one type, the two spirals (Sbc and Scd) make up a second, and the five remaining \"blue\" templates (Im, SB3, SB2, ssp25Myr, and ssp5Myr) make up a third type.  This grouping is somewhat ad-hoc, but does have physical motivation, in that we have observed that Ellipticals, spirals, and irregular/starburst galaxies do show distinctly evolving observed fractions as a function of apparent/absolute magnitude and redshift.  Things get more complicated with more complex SED sets that contain variations in dust content, star formation histories, emission lines, etc...  Due to such complications, the **current** implementation of `BPZliteInformer` leaves the assignment of a \"broad-SED-type\" to the user, and these broad types are a necessary input to `BPZliteInformer` via the `type_file` config option.  In the future, determination of broad SED type will be added as a pre-processing step to the rail_bpz package.\n",
    "\n",
    "The easiest way to obtain these broad SED types is to run `DESC_BPZ` with the parameter `ONLY_TYPE` set to `yes`.  When the `ONLY_TYPE` option is turned on in `DESC_BPZ`, the code returns a best-fit SED type evaluated only at the spectroscopic redshift for the object (determined as the best chi^2 amongst the N templates).  The user then needs to map these N integers down to a set of \"broad-type\" integers corresponding to however they wish to define the mapping from N SED types to M broad types.  As an example, I have done this using the CWWSB templates and the 1 Ell, 2 Sp, and 5 Im/SB broad type mapping for our `test_dc2_training_9816.hdf5` dataset. \n",
    "The file with these broad types, named `test_dc2_training_9816_broadtypes.hdf5` is available to download from NERSC, and for convenience, can be downloaded via the built-in RAIL command line tool with:<br>\n",
    "`!rail get-data --bpz-demo-data` in the cell below.\n",
    "\n",
    "\n",
    "The file `test_dc2_training_9816_broadtypes.hdf5` consists of an array of integers named `types` with values 0 (Elliptical), 1 (Spiral), and 2 (Irregular/Starburst) corresponding to the best-fit broad SED for each of the 10,225 galaxies in our training sample.\n",
    "\n",
    "Now, let's set up our inform stage to calculate a new prior.  We will name the new prior `test_9816_demo_prior.pkl`, setting this as the `model` config parameter will tell `BPZliteInformer` to save our trained model by that name in the current directory.\n",
    "\n",
    "When we run `inform` it will display values for the parameters as the minimizer runs, including final values for the parameters.  You do not need to pay attention to these values, though if you are curious you can plot them up and compare to the distributions of the HDFN prior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb0ad0-e657-4dbc-9373-fe6802d84bed",
   "metadata": {},
   "source": [
    "## First, as mentioned in the above cell, we must download the file containing the broad types for each galaxy in our training set.  You can do this by executing the `rail get-data --bpz-demo-data` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66893800-e796-4c28-8c52-683f6e32a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rail get-data --bpz-demo-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a283f01-f110-436c-9bf1-ec9d702782f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = dict(hdf5_groupname=\"photometry\", model=\"test_9816_demo_prior.pkl\",\n",
    "                 type_file=os.path.join(RAILDIR, \"rail/examples_data/estimation_data/data/test_dc2_training_9816_broadtypes.hdf5\"),\n",
    "                 nt_array=[1,2,5])\n",
    "run_bpz_train = BPZliteInformer.make_stage(name=\"bpz_new_prior\", **train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e34ec-19d2-4be6-9c06-35574d5fd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_bpz_train.inform(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76adebff-ee70-46a1-99d9-bfaf494b4e80",
   "metadata": {},
   "source": [
    "So, we've created a new prior named `test_9816_demo_prior.pkl` which should have appeared in this directory.  We can visualize the prior using the `prior_function` function from DESC_BPZ to generate prior values for our broad types.  We can compare our new prior to that of the default HDFN prior that we ran initially.  The model files simply store a set of parameters in a dictionary that `prior_function` uses to produce the prior values.\n",
    "\n",
    "**NOTE:** if you want to learn the meaning of these parameters, you can read the original BPZ paper, Benitez (2000) here: https://ui.adsabs.harvard.edu/abs/2000ApJ...536..571B/abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87139650-0404-4a83-8b5e-34328cbd5374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from desc_bpz.prior_from_dict import prior_function\n",
    "\n",
    "with open(hdfnfile, \"rb\") as f:\n",
    "    hdfnmodel = pickle.load(f)\n",
    "hdfnmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c748e5-316f-4d6d-b9ce-0ca7344d063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_9816_demo_prior.pkl\", \"rb\") as f:\n",
    "    newmodel = pickle.load(f)\n",
    "newmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e70cc21-cf62-4904-9eaf-6997573218b3",
   "metadata": {},
   "source": [
    "`prior_with_dict` takes four arguments: a redshift grid, a magnitude (it is an apparent magnitude-dependent prior), the modeldict, and the number of templates in our SED set as arguments.  Let's generate priors for mag=23, and then for mag=25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d073a1-7866-4379-8da3-f92f385447c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zgrid=np.linspace(0,3,301)\n",
    "defprior20 = prior_function(zgrid, 20., hdfnmodel, 8)\n",
    "defprior23 = prior_function(zgrid, 23., hdfnmodel, 8)\n",
    "defprior25 = prior_function(zgrid, 25., hdfnmodel, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22222b-7136-44b0-87d3-da324ccd5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "newprior23 = prior_function(zgrid, 23., newmodel, 8)\n",
    "newprior25 = prior_function(zgrid, 25., newmodel, 8)\n",
    "newprior20 = prior_function(zgrid, 20., newmodel, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8b995-829a-4737-8613-5da1c24f7bcb",
   "metadata": {},
   "source": [
    "We will plot the prior for the elliptical, one spiral, and one irregular to compare.  Note the BPZ divides up the probability in each broad type equally amongst the N templates in that broad type, so we will multiply by that number to get the total prior probability for the entire broad type, in our case 1 Elliptical SED, 2 Spiral SEDs, and 5 Irr/SB SEDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8eb57-1af4-4b3e-b479-6a75ec8bc1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seddict = {'El': 0, 'Sp': 1, 'Irr/SB': 7}\n",
    "multiplier = [1.0, 2.0, 5.0]\n",
    "sedcol = ['r', 'm', 'b']\n",
    "fig, (axs, axs2, axs3) = plt.subplots(3, 1, figsize=(10,12))\n",
    "for sed, col, multi in zip(seddict, sedcol, multiplier):\n",
    "    axs.plot(zgrid, defprior20[:,seddict[sed]]*multi, color=col, lw=2,ls='--', label=f\"hdfn prior {sed}\")\n",
    "    axs.plot(zgrid, newprior20[:,seddict[sed]]*multi, color=col, ls='-', label=f\"new prior {sed}\")\n",
    "    axs.set_title(\"priors for mag=20.0\")\n",
    "    axs2.plot(zgrid, defprior23[:,seddict[sed]]*multi, color=col, lw=2,ls='--', label=f\"hdfn prior {sed}\")\n",
    "    axs2.plot(zgrid, newprior23[:,seddict[sed]]*multi, color=col, ls='-', label=f\"new prior {sed}\")\n",
    "    axs2.set_title(\"priors for mag=23.0\")\n",
    "    axs3.plot(zgrid, defprior25[:,seddict[sed]]*multi, color=col, lw=2,ls='--', label=f\"hdfn prior {sed}\")\n",
    "    axs3.plot(zgrid, newprior25[:,seddict[sed]]*multi, color=col, ls='-', label=f\"new prior {sed}\")\n",
    "    axs3.set_xlabel(\"redshift\")\n",
    "    axs3.set_title(\"priors for mag=25.0\")\n",
    "    axs3.set_ylabel(\"prior_probability\")\n",
    "    axs.set_ylabel(\"prior probability\")\n",
    "axs.legend(loc=\"upper right\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b074cb1e-53bb-4953-82e3-1677667d4f5f",
   "metadata": {},
   "source": [
    "For the ellipticals and spirals at magnitudes 23 and 25, we see that the mean redshift and shape of the prior are similar, but the amplitudes are dramatically different: the HDFN prior is telling us that you are more likely to be an irregular/starburst galaxy than an elliptical or spiral at our two example magnitudes, whereas our custom prior has a higher probability for spirals at fainter magnitudes.  We also see that the custom prior is predicting a slightly different redshift distribution and higher mean redshift than the HDFN prior for irregular/starburst galaxies.  At magnitude 20 we see almost no probability of being an irregular galaxy in our custom prior.  In both priors, the probability of being an irregular/starburst increases dramatically as we go fainter in apparent magnitude, consistent with our expectations of galaxy evolution.\n",
    "\n",
    "The final posterior PDF is a product of the marginalized likelihood as a function of redshift and type, and thus the effect of the prior depends heavily on the \"peakiness\" of the likelihood: with a high chi^2 in flux/color space leading to very high likelihoods, the prior should not have a dramatic effect on the posterior.  For lower chi^2 values and galaxies with low S/N where the likelihoods are broad in redshift, the prior can have more dramatic results, often pushing the PDF to higher or lower redshifts.  The exception can be if the prior for a particular redshift or type goest to zero.  For example, our custom prior assigns almost zero prior probability of a galaxy being an irregular at 20th magnitude.  So, no matter how high the likelihood the prior is for one of the irregular templates, the prior will quash this and any probability from the elliptical or spiral templates is likely to dominate in the final marginalized posterior.  In general, the redshift distributions as a function of apparent magnitude become very broad at fainter magnitudes, and so this \"strong prior\" case only occurs at very bright apparent magnitudes.  Given the power law shape of apparent magnitude number counts, this means that this only affects a small number of galaxies.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0919d-5842-4297-9a03-3838c6be6a2c",
   "metadata": {},
   "source": [
    "Now, let's re-run BPZliteEstimator using this new prior and see if our results are any different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c43a9a-4afe-4d8b-8aeb-5cd4845bdbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_dict = dict(hdf5_groupname=\"photometry\", output=\"bpz_results_rerun.hdf5\", prior_band='mag_i_lsst',\n",
    "                 no_prior=False)\n",
    "rerun = BPZliteEstimator.make_stage(name=\"rerun_bpz\", **rerun_dict, \n",
    "                            model=run_bpz_train.get_handle('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd05674-9cb6-4c0f-94dc-f3947d711f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rerun.estimate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9e158-708c-4dc0-b763-838123eaabf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_res = qp.read(\"bpz_results_rerun.hdf5\")\n",
    "#rerun_res = qp.read(\"bpz_results_newprior_STANDALONE.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810b988-4c59-4a30-b0b9-8c2da6af76e1",
   "metadata": {},
   "source": [
    "And let's plot the modes fore this new run as well as our run with the default prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8380c0e-6632-42fd-ab7e-bfa057f68ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(sz, rerun_res.ancil['zmode'].flatten(), s=8, c='k', label='custom prior zmode')\n",
    "plt.scatter(sz, default_result.ancil['zmode'].flatten(), s=2, c='r', label='default prior mode')\n",
    "plt.plot([0,3], [0,3], 'b--')\n",
    "plt.xlabel(\"redshift\")\n",
    "plt.ylabel(\"photo-z mode\")\n",
    "plt.legend(loc='upper center', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a724ac-853c-45e7-babc-0679d05072e0",
   "metadata": {},
   "source": [
    "We generally consistent performance, but with small shifts (particularly at higher redshift), and some noticeable changes in the outliers.  This is about what we would expect, as our priors are fairly broad, and the redshif/type distributions for our cosmoDC2 data is not massively different than that described by the HDFN prior (except at very bright magnitudes, which may just be due to very small numbers of those bright galaxies in our training set, and which only affects a very small portion of our test sample, e.g. only 318 of our test_sample galaxies have `mag_i_lsst < 21.0`). Overall, the Bayesian prior should only have a dramatic effect on low S/N galaxies with fairly broad PDFs. For high S/N galaxies like those in our \"gold\" sample tested here, the chi^2 and likelihood values should dominate, and the prior should mostly cause minor changes.  The exception can be on bimodal PDFs, where the prior may increase one peak and decrease the other, moving the mode from a catastrophic outlier to a reasonable estimate, or vice-versa.  Let's find the indeces for objects with very large differences between our two estimates and plot one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84134c86-f752-49c1-aa6a-cf48a6e999f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_mode = rerun_res.ancil['zmode'].flatten() - default_result.ancil['zmode'].flatten()\n",
    "largedelta = (np.abs(delta_mode)>2.5)\n",
    "print(f\"{np.sum(largedelta)} gals have large shift in mode with indices:\\n\\n\")\n",
    "for i, delt in enumerate(largedelta):\n",
    "    if delt:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b948437-994c-4a57-bf43-c775159fcb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "whichone = 109\n",
    "fig, axs = plt.subplots(1,1, figsize=(10,6))\n",
    "default_result.plot_native(key=whichone, axes=axs, label=\"CWWHDFN prior\")\n",
    "rerun_res.plot_native(key=whichone, axes=axs, label=\"custom prior\")\n",
    "axs.set_xlabel(\"redshift\")\n",
    "axs.set_ylabel(\"PDF\")\n",
    "axs.legend(loc=\"upper center\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af967c-514a-409e-9e0f-5bd9f6fce111",
   "metadata": {},
   "source": [
    "Yes, the difference in prior has modulated the amplitude in the two peaks slightly, shifting the mode from low redshift peak for CWWHDFN to the high redshift peak for the custom prior.  While the mode has changed dramatically, both PDFs still have significant probability at both potential redshift solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10aad14-fa9f-4bf4-86a6-1afa27d8f3c9",
   "metadata": {},
   "source": [
    "## Point estimate metrics\n",
    "\n",
    "Let's see if our point estimate metrics have improved at all given the tuned prior.  These metrics take in arrays of the point estimates (we'll use the mode) and the true redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a1e03-7eac-4c18-965d-3121cd33e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.evaluation.metrics.pointestimates import PointSigmaIQR, PointBias, PointOutlierRate, PointSigmaMAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf679db-395e-4e95-865b-2091a3d147eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfn_sigma_eval = PointSigmaIQR(default_result.ancil['zmode'].flatten(), sz)\n",
    "rerun_sigma_eval = PointSigmaIQR(rerun_res.ancil['zmode'].flatten(), sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014cfef9-9097-4b07-9463-804c30b38f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfn_sigma = hdfn_sigma_eval.evaluate()\n",
    "rerun_sigma = rerun_sigma_eval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43179c-006f-42c9-afc8-ca794b26dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hdfn sigma: %.4f \\ncustom prior sigma: %.4f\" % (hdfn_sigma, rerun_sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95d4ff-1a8d-4b75-8229-0616da64d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfn_bias_eval = PointBias(default_result.ancil['zmode'].flatten(), sz)\n",
    "rerun_bias_eval = PointBias(rerun_res.ancil['zmode'].flatten(), sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba063f56-d078-477e-8227-c160a7552233",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfn_bias = hdfn_bias_eval.evaluate()\n",
    "rerun_bias = rerun_bias_eval.evaluate()\n",
    "print(\"hdfn bias: %.4f \\ncustom prior bias: %.4f\" % (hdfn_bias, rerun_bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d16539-73da-4e19-9965-c7ea468b08de",
   "metadata": {},
   "source": [
    "We see very minor reductions, and overall similar behavior.  Again, the prior should not affect high S/N observations very much.  From our plot it looks like the outlier fraction may be the metric most affected by the prior, let's check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f366d-45a0-4f7a-928b-2e71962f9d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfn_outlier_eval = PointOutlierRate(default_result.ancil['zmode'].flatten(), sz)\n",
    "rerun_outlier_eval = PointOutlierRate(rerun_res.ancil['zmode'].flatten(), sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068610e9-c213-478d-92de-edd2adca0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfn_outlier = hdfn_outlier_eval.evaluate()\n",
    "rerun_outlier = rerun_outlier_eval.evaluate()\n",
    "print(\"hdfn outlier rate: %.4f \\ncustom prior outlier rate: %.4f\" % (hdfn_outlier, rerun_outlier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771fda8f-f89b-4d98-aedd-cfcde34389f4",
   "metadata": {},
   "source": [
    "Not a dramatic effect, but a definite reduction in the number of outliers.  This outlier rate is defined in terms of PointSigmaIQR, and thus varies depending on said sigma, and is thus harder to directly compare.  For a direct comparison, let's compute the fraction of galaxies that have a delta(zmode - specz) larger than 0.15*(1+z), i.e. those with abs(zmode - specz) / (1 + specz) > 0.15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b354702-02c0-4d3a-b0d0-92e3a3c9d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.evaluation.metrics.pointestimates import PointStatsEz\n",
    "hdfn_ez_eval = PointStatsEz(default_result.ancil['zmode'].flatten(), sz)\n",
    "rerun_ez_eval = PointStatsEz(rerun_res.ancil['zmode'].flatten(), sz)\n",
    "hdfn_ez = hdfn_ez_eval.evaluate()\n",
    "rerun_ez = rerun_ez_eval.evaluate()\n",
    "hdfn_outlier_frac = (np.sum((np.abs(hdfn_ez) > 0.15))) / len(sz)\n",
    "rerun_outlier_frac = (np.sum((np.abs(rerun_ez) > 0.15))) / len(sz)\n",
    "print(\"HDFN catastrophic outlier frac is: %.4f\\ncustom prior catastrophic oulier frac is: %.4f\" % (hdfn_outlier_frac, rerun_outlier_frac))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3e1a9-6431-4d14-b4a8-3b88f6259204",
   "metadata": {},
   "source": [
    "So, our custom prior has some effect on results, but it does not dominate.  That is a good thing, as again, we do not want our prior to dominate photo-z calculations for high signal-to-noise data.  Also, in all cases above we are using the same template set, and the template set used is also part of the implicit prior of the code, and can have a much larger effect on the results: our chi^2 values, and thus likelihoods for each galaxy at each redshift, are measured relative to the fluxes predicted for the templates.  The combination of the templates and prior, and optimization of both will influence resultant photo-z performance.  However, optimization of SED template sets is beyond the scope of this simple demo notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
