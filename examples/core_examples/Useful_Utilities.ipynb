{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Utilities\n",
    "\n",
    "**Authors:** Olivia Lynn, Eric Charles, Sam Schmidt, Alex Malz\n",
    "\n",
    "**Last Run Sucessfully:** August 3, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import_and_attach_all\n",
    "\n",
    "explain\n",
    "note that it's a useful shortcut, but slower, and imports stuff you'll never need (but helpful for notebooks esp)\n",
    "vs as you become more advanced user you can do more specific imports\n",
    "also mention how they put the classes directly in namespace, so you don't have to do rail.creation.etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported rail.hub\n",
      "Imported rail.astro_tools\n",
      "Imported rail.core\n",
      "Imported rail.stages\n",
      "Imported rail.bpz\n",
      "Imported rail.cmnn\n",
      "Imported rail.delight\n",
      "Failed to import rail.dsps because: You need to have the SPS_HOME environment variable\n",
      "Imported rail.flexzboost\n",
      "Failed to import rail.gpz because: No module named 'rail.estimation.algos.gpz_v1'\n",
      "Imported rail.pipelines\n",
      "Failed to import rail.pzflow because: No module named 'rail.estimation.algos.pzflow'\n",
      "Imported rail.sklearn\n",
      "Imported rail.som\n",
      "Attached 10 base classes and 46 fully formed stages to rail.stages\n"
     ]
    }
   ],
   "source": [
    "import rail\n",
    "import ceci\n",
    "import rail.stages\n",
    "\n",
    "from rail.core.utils import RAILDIR\n",
    "rail.stages.import_and_attach_all()\n",
    "from rail.stages import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - explain this, and how at first it'll be empty, but that we'll run it later and see\n",
    "# this keeps track of (ASK or check) (the things we put in the data store? the file handles? all of the above?)\n",
    "DS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a pipeline to use\n",
    "\n",
    "# TODO - explain find_rail_file\n",
    "\n",
    "# we could do:\n",
    "flow_file = os.path.join(\n",
    "    RAILDIR, \"rail/examples_data/goldenspike_data/data/pretrained_flow.pkl\"\n",
    ")\n",
    "\n",
    "# but if we don't know where our file is, or we're just kinda lazy:\n",
    "from rail.core.utils import find_rail_file\n",
    "flow_file = find_rail_file('examples_data/goldenspike_data/data/pretrained_flow.pkl')\n",
    "#os.environ['FLOWDIR'] = os.path.dirname(flow_file) # this was in the block i copy/pasted, but maybe throw out?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bands = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "rename_dict = {f\"mag_{band}_lsst_err\": f\"mag_err_{band}_lsst\" for band in bands}\n",
    "post_grid = [float(x) for x in np.linspace(0.0, 5, 21)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  model: /Users/orl/code/DESC-RAIL/rail_base/src/rail/examples_data/goldenspike_data/data/pretrained_flow.pkl, flow_engine_test\n"
     ]
    }
   ],
   "source": [
    "flow_engine_test = FlowCreator.make_stage(\n",
    "    name=\"flow_engine_test\", model=flow_file, n_samples=50\n",
    ")\n",
    "col_remapper_test = ColumnMapper.make_stage(\n",
    "    name=\"col_remapper_test\", hdf5_groupname=\"\", columns=rename_dict\n",
    ")\n",
    "#flow_engine_test.sample(6, seed=0).data\n",
    "\n",
    "pipe = ceci.Pipeline.interactive()\n",
    "stages = [flow_engine_test, col_remapper_test]\n",
    "for stage in stages:\n",
    "    pipe.add_stage(stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output_flow_engine_test: inprogress_output_flow_engine_test.pq, flow_engine_test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_remapper_test.connect_input(flow_engine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods of introspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'output_flow_engine_test'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO add code + explanation of eric's introspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flow_engine_test', 'col_remapper_test']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the names of the stages\n",
    "pipe.stage_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StageConfig{output_mode:default,n_samples:50,seed:12345,name:flow_engine_test,model:/Users/orl/code/DESC-RAIL/rail_base/src/rail/examples_data/goldenspike_data/data/pretrained_flow.pkl,config:None,aliases:{'output': 'output_flow_engine_test'},}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the configuration of a particular stage\n",
    "pipe.flow_engine_test.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StageConfig{output_mode:default,n_samples:50,seed:42,name:flow_engine_test,model:/Users/orl/code/DESC-RAIL/rail_base/src/rail/examples_data/goldenspike_data/data/pretrained_flow.pkl,config:None,aliases:{'output': 'output_flow_engine_test'},}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - is this a logical place to mention this?\n",
    "# Update a particular config value once the stage has been created\n",
    "pipe.flow_engine_test.config.update(seed=42)\n",
    "pipe.flow_engine_test.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('output', rail.core.data.PqHandle)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of outputs 'tags'\n",
    "# These are how the stage thinks of the outputs, as a list names associated to DataHandle types.\n",
    "pipe.flow_engine_test.outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_flow_engine_test': 'output_flow_engine_test.pq'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of outputs 'aliased tags'\n",
    "# These are how the pipeline things of the outputs, as a unique key that points to a particular file\n",
    "pipe.flow_engine_test._outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping stage flow_engine_test because its outputs exist already\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(({'col_remapper_test': <Job col_remapper_test>},\n",
       "  [Stage that applies remaps the following column names in a pandas DataFrame:\n",
       "   f{str(self.config.columns)}]),\n",
       " {'output_dir': '.', 'log_dir': '.', 'resume': True})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - talk about resume=True\n",
    "# notes: adding resume=True to pipe.initialize skips stages that already have existing output files\n",
    "pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=True), None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rail.creation.engines.flowEngine.FlowCreator at 0x29613bc50>,\n",
       " Stage that applies remaps the following column names in a pandas DataFrame:\n",
       " f{str(self.config.columns)}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - run this after initializing the pipeline, should show order of classes / \"all the stages this pipeline will run\"\n",
    "pipe.stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO explain RailStage.pipeline_stages\n",
    "\n",
    "note that this will only look at what stages you've imported, which is not necessarily all stages in rail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rail.estimation.estimator.CatEstimator'>\n",
      "<class 'rail.estimation.algos.random_gauss.RandomGaussEstimator'>\n",
      "<class 'rail.estimation.algos.train_z.TrainZEstimator'>\n",
      "<class 'rail.estimation.algos.bpz_lite.BPZliteEstimator'>\n",
      "<class 'rail.estimation.algos.cmnn.CMNNPDF'>\n",
      "<class 'rail.estimation.algos.flexzboost.FlexZBoostEstimator'>\n",
      "<class 'rail.estimation.algos.k_nearneigh.KNearNeighEstimator'>\n",
      "<class 'rail.estimation.algos.sklearn_neurnet.SklNeurNetEstimator'>\n",
      "<class 'rail.estimation.algos.nz_dir.NZDirSummarizer'>\n"
     ]
    }
   ],
   "source": [
    "for val in RailStage.pipeline_stages.values():\n",
    "    if issubclass(val[0], rail.estimation.estimator.CatEstimator):\n",
    "        print(val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO talk about dir() -> is there a better way to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add_stage',\n",
       " 'build_config',\n",
       " 'build_dag',\n",
       " 'build_stage',\n",
       " 'callback',\n",
       " 'create',\n",
       " 'enqueue_job',\n",
       " 'find_all_outputs',\n",
       " 'get_stage_aliases',\n",
       " 'global_config',\n",
       " 'initialize',\n",
       " 'initiate_run',\n",
       " 'interactive',\n",
       " 'launcher_config',\n",
       " 'make_flow_chart',\n",
       " 'modules',\n",
       " 'ordered_stages',\n",
       " 'overall_inputs',\n",
       " 'pipeline_files',\n",
       " 'pipeline_outputs',\n",
       " 'print_stages',\n",
       " 'read',\n",
       " 'remove_stage',\n",
       " 'run',\n",
       " 'run_config',\n",
       " 'run_info',\n",
       " 'run_jobs',\n",
       " 'save',\n",
       " 'should_skip_stage',\n",
       " 'sleep',\n",
       " 'stage_config_data',\n",
       " 'stage_execution_config',\n",
       " 'stage_names',\n",
       " 'stages',\n",
       " 'stages_config']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notes: this includes (**ASK**) methods you can call and parameters you can set\n",
    "dir(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - write this out\n",
    "# locally modilfy your .gitattributes to keep from committing notebook output \n",
    "# https://stackoverflow.com/questions/28908319/how-to-clear-jupyter-notebooks-output-in-all-cells-from-the-linux-terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
